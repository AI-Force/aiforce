{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp tools.check_double_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import hashlib\n",
    "import logging\n",
    "import logging.handlers\n",
    "import argparse\n",
    "import sys\n",
    "from os import listdir, remove\n",
    "from os.path import join, isfile, isdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "BUF_SIZE = 65536  # lets read stuff in 64kb chunks!\n",
    "\n",
    "FILE_FILTER = ['.DS_Store']\n",
    "IMAGE_EXTENSION = '.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double File Checker\n",
    "\n",
    "> Checks a given folder and subfolders for double files by calculating the corresponding SHA1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class DoubleFileChecker:\n",
    "    \"\"\"\n",
    "    Checks a given folder and subfolders for double files by calculating the corresponding SHA1.\n",
    "    `path`: the folder to process\n",
    "    `reverse`: if True, order the file reverse\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path, reverse=False):\n",
    "        self.path = path\n",
    "        self.reverse = reverse\n",
    "\n",
    "    def check(self):\n",
    "        \"\"\"\n",
    "        The main validation logic.\n",
    "        \"\"\"\n",
    "\n",
    "        images = scan_folder(self.path)\n",
    "        images.sort(key=len, reverse=self.reverse)\n",
    "        all_images = len(images)\n",
    "        contents = []\n",
    "        delete_entries = []\n",
    "\n",
    "        for index, image in enumerate(images):\n",
    "            logger.info(\"{} / {} - Handle Image {}\".format(index + 1, all_images, image))\n",
    "            content = (image, get_file_sha(image))\n",
    "            contents.append(content)\n",
    "\n",
    "        # Check double entries\n",
    "        logger.info('Checking Double Entries:')\n",
    "        double_entries = check_double_entries(contents)\n",
    "\n",
    "        logger.info(\"Found {} Entries:\".format(len(double_entries)))\n",
    "        for (key, entrylist) in double_entries.items():\n",
    "            logger.info(\"{}:\".format(key))\n",
    "            for entry in list(entrylist):\n",
    "                logger.info(\"-> {}\".format(entry[0]))\n",
    "\n",
    "        if len(double_entries) > 0:\n",
    "            logger.info('Using only the first of each double entries.')\n",
    "            delete_files = input('Will you delete the ignored double files from source? (y/n) ')\n",
    "            delete_files = delete_files == 'y'\n",
    "            for (key, entry) in double_entries.items():\n",
    "                entry = list(entry)\n",
    "                delete_entries += entry[1:]\n",
    "            remove_entries(contents, delete_entries, delete_files)\n",
    "        return contents, delete_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(DoubleFileChecker.check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def configure_logging(logging_level=logging.INFO):\n",
    "    \"\"\"\n",
    "    Configures logging for the system.\n",
    "\n",
    "    :param logging_level: The logging level to use.\n",
    "    \"\"\"\n",
    "    logger.setLevel(logging_level)\n",
    "\n",
    "    handler = logging.StreamHandler(sys.stdout)\n",
    "    handler.setLevel(logging_level)\n",
    "\n",
    "    logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_file_sha(fname):\n",
    "    \"\"\"\n",
    "    Calculates the SHA1 of a given file.\n",
    "    `fname`: the file path\n",
    "    return: the calculated SHA1 as hex\n",
    "    \"\"\"\n",
    "\n",
    "    result = ''\n",
    "    if isfile(fname):\n",
    "        sha1 = hashlib.sha1()\n",
    "        with open(fname, 'rb') as f:\n",
    "            while True:\n",
    "                data = f.read(BUF_SIZE)\n",
    "                if not data:\n",
    "                    break\n",
    "                sha1.update(data)\n",
    "            result = sha1.hexdigest()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def check_double_entries(entries):\n",
    "    \"\"\"\n",
    "    Process a list of tuples of filenames and corresponding hash for double hashes.\n",
    "    `entries`: the list of entries with their hashes\n",
    "    returns: a dictionary containing double entries by hash\n",
    "    \"\"\"\n",
    "\n",
    "    hashes = dict()\n",
    "    for entry in entries:\n",
    "        h = entry[1]\n",
    "        if h not in hashes:\n",
    "            hashes[h] = []\n",
    "        hashes[h].append(entry)\n",
    "\n",
    "    double_hashes = dict()\n",
    "    for (key, entrylist) in hashes.items():\n",
    "        if len(entrylist) > 1:\n",
    "            double_hashes[key] = entrylist\n",
    "    return double_hashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def remove_entries(entries, to_remove, delete_source=False):\n",
    "    \"\"\"\n",
    "    Removes entries from list and optionally remove the source file as well.\n",
    "    `entries`: the list of entries to remove from\n",
    "    `to_remove`: the list of entries to remove\n",
    "    `delete_source`: werether or not to delete the source file as well\n",
    "    returns: a list of resulting entries\n",
    "    \"\"\"\n",
    "\n",
    "    for entry in to_remove:\n",
    "        if entry in entries:\n",
    "            index = entries.index(entry)\n",
    "            logger.info(\"Remove Entry: ({}) {}\".format(index, entry[0]))\n",
    "            del entries[index]\n",
    "            if delete_source:\n",
    "                logger.info(\"Delete Source File: \".format(entry[0]))\n",
    "                remove(entry[0])\n",
    "\n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def scan_folder(folder):\n",
    "    \"\"\"\n",
    "    Scans a folder and subfolders for image content.\n",
    "    `folder`: the folder to scan\n",
    "    returns: a list of paths to images found\n",
    "    \"\"\"\n",
    "    images = []\n",
    "\n",
    "    contents = listdir(folder)\n",
    "    for content in contents:\n",
    "        if content in FILE_FILTER:\n",
    "            continue\n",
    "        path = join(folder, content)\n",
    "        if isdir(path):\n",
    "            result = scan_folder(path)\n",
    "            for entry in result:\n",
    "                images.append(entry)\n",
    "        elif isfile(path):\n",
    "            images.append(path)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run from command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the data-set builder from command line, use the following command:\n",
    "`python -m mlcore.tools.check_double_images [parameters]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following parameters are supported:\n",
    "- `[folder]`: The folder to scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "if __name__ == '__main__' and '__file__' in globals():\n",
    "    configure_logging()\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"folder\", help=\"The folder to scan.\")\n",
    "    parser.add_argument(\"--reverse-sort\",\n",
    "                        help=\"If the double entries should be sorted reverse by length.\",\n",
    "                        default=False,\n",
    "                        action=\"store_true\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    checker = DoubleFileChecker(args.folder, args.reverse_sort)\n",
    "    checker.check()\n",
    "\n",
    "    logger.info('FINISHED!!!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML-Core]",
   "language": "python",
   "name": "conda-env-ML-Core-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
