{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp annotation.via_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import json\n",
    "import csv\n",
    "import shutil\n",
    "import logging\n",
    "from os.path import join, splitext, getsize, basename, isfile\n",
    "from aiforce.core import assign_arg_prefix\n",
    "from aiforce.annotation.core import Annotation, AnnotationAdapter, Region, RegionShape, parse_region_shape, SubsetType\n",
    "from aiforce.io.core import create_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "DEFAULT_ANNOTATIONS_FILE = 'via_region_data.json'\n",
    "DEFAULT_CATEGORY_LABEL_KEY = 'category'\n",
    "CSV_FIELDNAMES_V1 = ['#filename', 'file_size', 'file_attributes', 'region_count', 'region_id', 'region_shape_attributes',\n",
    "                     'region_attributes']\n",
    "CSV_FIELDNAMES_V2 = ['filename'] + CSV_FIELDNAMES_V1[1:]\n",
    "JSON_FIELDNAMES_V2 = {'filename': '', 'size': 0, 'regions': '[]', 'file_attributes': '{}'}\n",
    "JSON_FIELDNAMES_V1 = dict(JSON_FIELDNAMES_V2).update({'regions': '{}', 'fileref': '', 'base64_img_data': ''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIA Annotation Adapter\n",
    "> VIA annotation adapter. To use the VIA annotation tool, refer to the [Homepage](http://www.robots.ox.ac.uk/~vgg/software/via/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current supported annotations:\n",
    "- circle\n",
    "- ellipse\n",
    "- point\n",
    "- polygon\n",
    "- polyline\n",
    "- rectangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current supported annotation tool versions:\n",
    "- [VIA version 1 (v1.0.6)](https://www.robots.ox.ac.uk/~vgg/software/via/via-1.0.6.html)\n",
    "- [VIA version 2 (v2.0.11)](https://www.robots.ox.ac.uk/~vgg/software/via/via.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adapter has the following parameters:\n",
    "- `--path`: the path to the base folder containing the annotations (e.g.: *data/image_object_detection/my_collection*)\n",
    "- `--version`: The version format to read or write the anotations. If not set, parse the annotation-format on read, use version *2* on write annotation\n",
    "- `--categories_file_name`: The path to the categories file if not set, default to *categories.txt*\n",
    "- `--annotations_file_name`: The name of annotations file. If not set, default to *via_region_data.json*\n",
    "- `--category_label_key`: The key, the category label key is stored in the annotation file, default to *category*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AnnotationAdapter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c5e42b6279ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mVIAAnnotationAdapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAnnotationAdapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \"\"\"\n\u001b[1;32m      4\u001b[0m     \u001b[0mAdapter\u001b[0m \u001b[0mto\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwrite\u001b[0m \u001b[0mannotations\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mVIA\u001b[0m \u001b[0mannotation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AnnotationAdapter' is not defined"
     ]
    }
   ],
   "source": [
    "# export\n",
    "class VIAAnnotationAdapter(AnnotationAdapter):\n",
    "    \"\"\"\n",
    "    Adapter to read and write annotations in the VIA annotation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path, version=None, categories_file_name=None, annotations_file_name=None, category_label_key=None):\n",
    "        \"\"\"\n",
    "        VIA Adapter to read and write annotations.\n",
    "        `path`: the folder containing the annotations\n",
    "        `version`: the VIA version to use\n",
    "        `categories_file_name`: the name of the categories file\n",
    "        `annotations_file_name`: the name of annotations file\n",
    "        `category_label_key`: the key of the category label\n",
    "        \"\"\"\n",
    "        super().__init__(path, categories_file_name)\n",
    "        self.version = version\n",
    "        if annotations_file_name is None:\n",
    "            self.annotations_file_name = DEFAULT_ANNOTATIONS_FILE\n",
    "        else:\n",
    "            self.annotations_file_name = annotations_file_name\n",
    "\n",
    "        if category_label_key is None:\n",
    "            self.category_label_key = DEFAULT_CATEGORY_LABEL_KEY\n",
    "        else:\n",
    "            self.category_label_key = category_label_key\n",
    "\n",
    "    @classmethod\n",
    "    def argparse(cls, prefix=None):\n",
    "        \"\"\"\n",
    "        Returns the argument parser containing argument definition for command line use.\n",
    "        `prefix`: a parameter prefix to set, if needed\n",
    "        return: the argument parser\n",
    "        \"\"\"\n",
    "        parser = super(VIAAnnotationAdapter, cls).argparse(prefix=prefix)\n",
    "        parser.add_argument(assign_arg_prefix('--version', prefix),\n",
    "                            dest=\"version\",\n",
    "                            type=int,\n",
    "                            help=\"The version format to read or write the anotations.\",\n",
    "                            default=None)\n",
    "        parser.add_argument(assign_arg_prefix('--annotations_file_name', prefix),\n",
    "                            dest=\"annotations_file_name\",\n",
    "                            help=\"The name of annotations file.\",\n",
    "                            default=None)\n",
    "        parser.add_argument(assign_arg_prefix('--category_label_key', prefix),\n",
    "                            dest=\"category_label_key\",\n",
    "                            help=\"The key of the category label.\",\n",
    "                            default=None)\n",
    "\n",
    "        return parser\n",
    "\n",
    "    def read_annotations(self, subset_type=SubsetType.TRAINVAL):\n",
    "        \"\"\"\n",
    "        Reads a VIA annotations file.\n",
    "        Supports JSON and CSV file format.\n",
    "        `subset_type`: the subset type to read\n",
    "        return: the annotations as dictionary\n",
    "        \"\"\"\n",
    "        path = join(self.path, str(subset_type))\n",
    "        annotations_file_name = self._annotation_file_name_suffix_handling(subset_type)\n",
    "        annotations_file_path = join(self.path, annotations_file_name)\n",
    "        logger.info('Read file sources from {}'.format(path))\n",
    "        logger.info('Read annotations from {}'.format(annotations_file_path))\n",
    "\n",
    "        file_extension = splitext(annotations_file_name)[1]\n",
    "\n",
    "        if file_extension.lower() == '.json':\n",
    "            logger.info('Read VIA annotations in JSON format')\n",
    "            annotations = self._read_annotations_json(path, annotations_file_path)\n",
    "        elif file_extension.lower() == '.csv':\n",
    "            logger.info('Read VIA annotations in CSV format')\n",
    "            annotations = self._read_annotations_csv(path, annotations_file_path)\n",
    "        else:\n",
    "            message = 'Unsupported annotation format at {}'.format(annotations_file_path)\n",
    "            logger.error(message)\n",
    "            raise ValueError(message)\n",
    "\n",
    "        return annotations\n",
    "\n",
    "    def _read_annotations_csv(self, path, annotations_file_path):\n",
    "        \"\"\"\n",
    "        Reads a VIA CSV annotations file.\n",
    "        `path`: the path to read file sources from\n",
    "        `annotation_file_path`: the path to the annotations file\n",
    "        return: the annotations as dictionary\n",
    "        \"\"\"\n",
    "        annotations = {}\n",
    "        with open(annotations_file_path, newline='') as csv_file:\n",
    "            reader = csv.DictReader(csv_file)\n",
    "\n",
    "            # try parse the version if not set explicitly\n",
    "            if self.version is None:\n",
    "                logger.info('VIA version not set, try to detect')\n",
    "                # default is v2\n",
    "                self.version = 1 if reader.fieldnames[0] == CSV_FIELDNAMES_V1[0] else 2\n",
    "\n",
    "            logger.info('Use VIA version {}'.format(self.version))\n",
    "\n",
    "            fieldnames = CSV_FIELDNAMES_V1 if self.version == 1 else CSV_FIELDNAMES_V2\n",
    "            skipped_annotations = []\n",
    "            for row in reader:\n",
    "                file_path = join(path, row[fieldnames[0]])\n",
    "                if not isfile(file_path):\n",
    "                    logger.warning(\"{}: Source file not found, skip annotation.\".format(file_path))\n",
    "                    skipped_annotations.append(file_path)\n",
    "                    continue\n",
    "\n",
    "                annotation_id = \"{}{}\".format(row[fieldnames[0]], row[fieldnames[1]])\n",
    "\n",
    "                if annotation_id not in annotations:\n",
    "                    annotations[annotation_id] = Annotation(annotation_id=annotation_id, file_path=file_path)\n",
    "\n",
    "                annotation = annotations[annotation_id]\n",
    "\n",
    "                region_shape_attributes = json.loads(row[fieldnames[5]])\n",
    "                region = self._parse_region_shape_attributes(region_shape_attributes)\n",
    "                region_attributes = json.loads(row[fieldnames[6]])\n",
    "                category = None\n",
    "                if region_attributes and self.category_label_key in region_attributes:\n",
    "                    category = region_attributes[self.category_label_key]\n",
    "                region.labels = [category] if category else []\n",
    "                annotation.regions.append(region)\n",
    "\n",
    "        logger.info('Finished read annotations')\n",
    "        logger.info('Annotations read: {}'.format(len(annotations)))\n",
    "        if skipped_annotations:\n",
    "            logger.info('Annotations skipped: {}'.format(len(skipped_annotations)))\n",
    "\n",
    "        return annotations\n",
    "\n",
    "    def _read_annotations_json(self, path, annotations_file_path):\n",
    "        \"\"\"\n",
    "        Reads a VIA JSON annotations file.\n",
    "        `path`: the path to read file sources from\n",
    "        `annotation_file_path`: the path to the annotations file\n",
    "        return: the annotations as dictionary\n",
    "        \"\"\"\n",
    "        annotations = {}\n",
    "\n",
    "        with open(annotations_file_path) as json_file:\n",
    "            via_annotations = json.load(json_file)\n",
    "\n",
    "            # try parse the version if not set explicitly\n",
    "            if self.version is None:\n",
    "                logger.info('VIA version not set, try to detect')\n",
    "                values = via_annotations.values()\n",
    "                # default is v2\n",
    "                self.version = 1 if len(values) and isinstance(values[0]['regions'], dict) else 2\n",
    "\n",
    "            logger.info('Use VIA version {}'.format(self.version))\n",
    "\n",
    "            skipped_annotations = []\n",
    "            for data in via_annotations.values():\n",
    "                file_path = join(path, data['filename'])\n",
    "                if not isfile(file_path):\n",
    "                    logger.warning(\"{}: Source file not found, skip annotation.\".format(file_path))\n",
    "                    skipped_annotations.append(file_path)\n",
    "                    continue\n",
    "\n",
    "                annotation_id = \"{}{}\".format(data['filename'], data['size'])\n",
    "\n",
    "                if annotation_id not in annotations:\n",
    "                    annotations[annotation_id] = Annotation(annotation_id=annotation_id, file_path=file_path)\n",
    "\n",
    "                annotation = annotations[annotation_id]\n",
    "\n",
    "                regions = data['regions'].values() if self.version == 1 else data['regions']\n",
    "                for region_data in regions:\n",
    "                    region_shape_attributes = region_data['shape_attributes']\n",
    "                    region = self._parse_region_shape_attributes(region_shape_attributes)\n",
    "                    region_attributes = region_data['region_attributes']\n",
    "                    category = None\n",
    "                    if region_attributes and self.category_label_key in region_attributes:\n",
    "                        category = region_attributes[self.category_label_key]\n",
    "                    region.labels = [category] if category else []\n",
    "                    annotation.regions.append(region)\n",
    "\n",
    "        logger.info('Finished read annotations')\n",
    "        logger.info('Annotations read: {}'.format(len(annotations)))\n",
    "        if skipped_annotations:\n",
    "            logger.info('Annotations skipped: {}'.format(len(skipped_annotations)))\n",
    "\n",
    "        return annotations\n",
    "\n",
    "    def write_annotations(self, annotations, subset_type=SubsetType.TRAINVAL):\n",
    "        \"\"\"\n",
    "        Writes a VIA annotations file and copy the corresponding source files.\n",
    "        Supports JSON and CSV file format.\n",
    "        Format is inferred from the annotations_file setting.\n",
    "        `annotations`: the annotations as dictionary\n",
    "        `subset_type`: the subset type to write\n",
    "        return: a list of written target file paths\n",
    "        \"\"\"\n",
    "        path = join(self.path, str(subset_type))\n",
    "        target_folder = create_folder(path)\n",
    "        annotations_file_name = self._annotation_file_name_suffix_handling(subset_type)\n",
    "        annotations_file_path = join(self.path, annotations_file_name)\n",
    "        logger.info('Write file sources to {}'.format(target_folder))\n",
    "        logger.info('Write annotations to {}'.format(annotations_file_path))\n",
    "\n",
    "        file_extension = splitext(annotations_file_name)[1]\n",
    "\n",
    "        if file_extension.lower() == '.json':\n",
    "            logger.info('Write VIA annotations in JSON format')\n",
    "            copied_files = self._write_annotations_json(path, annotations_file_path, annotations)\n",
    "        elif file_extension.lower() == '.csv':\n",
    "            logger.info('Write VIA annotations in CSV format')\n",
    "            copied_files = self._write_annotations_csv(path, annotations_file_path, annotations)\n",
    "        else:\n",
    "            message = 'Unsupported annotation format at {}'.format(annotations_file_path)\n",
    "            logger.error(message)\n",
    "            raise ValueError(message)\n",
    "        return copied_files\n",
    "\n",
    "    def _write_annotations_csv(self, path, annotations_file_path, annotations):\n",
    "        \"\"\"\n",
    "        Writes a VIA CSV annotations file and copy the corresponding source files.\n",
    "        `path`: the path to write file sources into\n",
    "        `annotation_file_path`: the path to the annotations file\n",
    "        `annotations`: the annotations to write\n",
    "        return: a list of written target file paths\n",
    "        \"\"\"\n",
    "        if self.version is None:\n",
    "            logger.info('VIA version not set, set to default version')\n",
    "            # default is v2\n",
    "            self.version = 2\n",
    "\n",
    "        logger.info('Use VIA version {}'.format(self.version))\n",
    "\n",
    "        fieldnames = CSV_FIELDNAMES_V1 if self.version == 1 else CSV_FIELDNAMES_V2\n",
    "\n",
    "        with open(annotations_file_path, 'w', newline='') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "\n",
    "            skipped_annotations = []\n",
    "            copied_files = []\n",
    "            for annotation in annotations.values():\n",
    "                target_file = join(path, basename(annotation.file_path))\n",
    "\n",
    "                if not isfile(annotation.file_path):\n",
    "                    logger.warning(\"{}: Source file not found, skip annotation.\".format(annotation.file_path))\n",
    "                    skipped_annotations.append(annotation.file_path)\n",
    "                    continue\n",
    "                if isfile(target_file):\n",
    "                    logger.warning(\"{}: Target file already exist, skip annotation.\".format(annotation.file_path))\n",
    "                    skipped_annotations.append(annotation.file_path)\n",
    "                    continue\n",
    "\n",
    "                file_size = getsize(annotation.file_path)\n",
    "                file_name = basename(annotation.file_path)\n",
    "                for index, region in enumerate(annotation.regions):\n",
    "                    region_shape_attributes = self._create_region_shape_attributes(region)\n",
    "                    region_attributes = {\n",
    "                        self.category_label_key: ' '.join(region.labels) if len(region.labels) else ''\n",
    "                    }\n",
    "                    values = [file_name, file_size, '{}', len(annotation.regions), str(index),\n",
    "                              json.dumps(region_shape_attributes), json.dumps(region_attributes)]\n",
    "                    writer.writerow(dict(zip(fieldnames, values)))\n",
    "\n",
    "                # copy the file\n",
    "                shutil.copy2(annotation.file_path, target_file)\n",
    "                copied_files.append(target_file)\n",
    "\n",
    "        logger.info('Finished write annotations')\n",
    "        logger.info('Annotations written: {}'.format(len(annotations) - len(skipped_annotations)))\n",
    "        if skipped_annotations:\n",
    "            logger.info('Annotations skipped: {}'.format(len(skipped_annotations)))\n",
    "        return copied_files\n",
    "\n",
    "    def _write_annotations_json(self, path, annotations_file_path, annotations):\n",
    "        \"\"\"\n",
    "        Writes a VIA JSON annotations file and copy the corresponding source files.\n",
    "        `path`: the path to write file sources into\n",
    "        `annotation_file_path`: the path to the annotations file\n",
    "        `annotations`: the annotations to write\n",
    "        return: a list of written target file paths\n",
    "        \"\"\"\n",
    "        json_annotations = {}\n",
    "        skipped_annotations = []\n",
    "        copied_files = []\n",
    "\n",
    "        if self.version is None:\n",
    "            logger.info('VIA version not set, set to default version')\n",
    "            # default is v2\n",
    "            self.version = 2\n",
    "\n",
    "        logger.info('Use VIA version {}'.format(self.version))\n",
    "\n",
    "        fieldnames = JSON_FIELDNAMES_V1 if self.version == 1 else JSON_FIELDNAMES_V2\n",
    "\n",
    "        for annotation in annotations.values():\n",
    "            target_file = join(path, basename(annotation.file_path))\n",
    "\n",
    "            if not isfile(annotation.file_path):\n",
    "                logger.warning(\"{}: Source file not found, skip annotation.\".format(annotation.file_path))\n",
    "                skipped_annotations.append(annotation.file_path)\n",
    "                continue\n",
    "            if isfile(target_file):\n",
    "                logger.warning(\"{}: Target file already exist, skip annotation.\".format(annotation.file_path))\n",
    "                skipped_annotations.append(annotation.file_path)\n",
    "                continue\n",
    "\n",
    "            file_size = getsize(annotation.file_path)\n",
    "            file_name = basename(annotation.file_path)\n",
    "            file_id = '{:s}{:d}'.format(file_name, file_size)\n",
    "            regions = [{\n",
    "                'shape_attributes': self._create_region_shape_attributes(region),\n",
    "                'region_attributes': {\n",
    "                    self.category_label_key: ' '.join(region.labels) if len(region.labels) else ''\n",
    "                }\n",
    "            } for region in annotation.regions]\n",
    "            json_annotations[file_id] = dict(fieldnames).update({\n",
    "                'size': file_size,\n",
    "                'filename': file_name,\n",
    "                \"regions\": {str(i): v for i, v in enumerate(regions)} if self.version == 1 else regions\n",
    "            })\n",
    "\n",
    "            # copy the file\n",
    "            shutil.copy2(annotation.file_path, target_file)\n",
    "            copied_files.append(target_file)\n",
    "\n",
    "        with open(annotations_file_path, 'w') as json_file:\n",
    "            json.dump(json_annotations, json_file)\n",
    "\n",
    "        logger.info('Finished write annotations')\n",
    "        logger.info('Annotations written: {}'.format(len(annotations) - len(skipped_annotations)))\n",
    "        if skipped_annotations:\n",
    "            logger.info('Annotations skipped: {}'.format(len(skipped_annotations)))\n",
    "        return copied_files\n",
    "\n",
    "    def _annotation_file_name_suffix_handling(self, subset_type):\n",
    "        \"\"\"\n",
    "        Handle annotations file name based on the subset type.\n",
    "        `subset_type`: the subset type to handle\n",
    "        return: the annotations file name\n",
    "        \"\"\"\n",
    "        file_name, ext = splitext(self.annotations_file_name)\n",
    "        if subset_type in [SubsetType.TRAIN, SubsetType.VAL] and not file_name.endswith(str(subset_type)):\n",
    "            suffix = \"_{}\".format(str(subset_type))\n",
    "            return \"{}{}{}\".format(file_name, suffix, ext)\n",
    "        return self.annotations_file_name\n",
    "\n",
    "    def _parse_region_shape_attributes(self, region_shape_attributes):\n",
    "        \"\"\"\n",
    "        Parse region shape attributes.\n",
    "        `region_shape_attributes`: the region shape attributes as dictionary\n",
    "        return: the corresponding annotation\n",
    "        \"\"\"\n",
    "        if not region_shape_attributes:\n",
    "            return Annotation()\n",
    "\n",
    "        region_shape = parse_region_shape(region_shape_attributes['name'])\n",
    "        points_x = None\n",
    "        points_y = None\n",
    "        radius_x = 0\n",
    "        radius_y = 0\n",
    "        rotation = 0\n",
    "        if region_shape == RegionShape.CIRCLE:\n",
    "            points_x = [region_shape_attributes['cx']]\n",
    "            points_y = [region_shape_attributes['cy']]\n",
    "            radius_x = region_shape_attributes['r']\n",
    "            radius_y = region_shape_attributes['r']\n",
    "        elif region_shape == RegionShape.ELLIPSE:\n",
    "            points_x = [region_shape_attributes['cx']]\n",
    "            points_y = [region_shape_attributes['cy']]\n",
    "            radius_x = region_shape_attributes['rx']\n",
    "            radius_y = region_shape_attributes['ry']\n",
    "            rotation = 0 if self.version == 1 else region_shape_attributes['theta']\n",
    "        elif region_shape == RegionShape.POINT:\n",
    "            points_x = [region_shape_attributes['cx']]\n",
    "            points_y = [region_shape_attributes['cy']]\n",
    "        elif region_shape == RegionShape.POLYGON:\n",
    "            points_x = region_shape_attributes['all_points_x']\n",
    "            points_y = region_shape_attributes['all_points_y']\n",
    "        elif region_shape == RegionShape.RECTANGLE:\n",
    "            x = region_shape_attributes['x']\n",
    "            y = region_shape_attributes['y']\n",
    "            width = region_shape_attributes['width']\n",
    "            height = region_shape_attributes['height']\n",
    "            points_x = [x, x + width]\n",
    "            points_y = [y, y + height]\n",
    "        return Region(shape=region_shape, points_x=points_x, points_y=points_y, radius_x=radius_x, radius_y=radius_y,\n",
    "                      rotation=rotation)\n",
    "\n",
    "    def _create_region_shape_attributes(self, region: Region):\n",
    "        \"\"\"\n",
    "        Create region shape attributes.\n",
    "        `region`: the region to create region shape attributes from\n",
    "        return: the corresponding region shape attributes as dictionary\n",
    "        \"\"\"\n",
    "        region_shape_attributes = {\n",
    "            \"name\": str(region.shape),\n",
    "\n",
    "        }\n",
    "        c_x = region.points_x[0] if len(region.points_x) else 0\n",
    "        c_y = region.points_y[0] if len(region.points_y) else 0\n",
    "\n",
    "        if region.shape == RegionShape.CIRCLE:\n",
    "            region_shape_attributes['cx'] = c_x\n",
    "            region_shape_attributes['cy'] = c_y\n",
    "            region_shape_attributes['r'] = max(region.radius_x, region.radius_y)\n",
    "        elif region.shape == RegionShape.ELLIPSE:\n",
    "            region_shape_attributes['cx'] = c_x\n",
    "            region_shape_attributes['cy'] = c_y\n",
    "            region_shape_attributes['rx'] = region.radius_x\n",
    "            region_shape_attributes['ry'] = region.radius_y\n",
    "            # version 1 do not support ellipse rotation\n",
    "            if self.version == 1 and region.rotation:\n",
    "                logger.warning(\"VIA version {} do not support rotation of shape {}. Rotation is set to 0.\".format(\n",
    "                    self.version,\n",
    "                    region.shape,\n",
    "                ))\n",
    "            else:\n",
    "                region_shape_attributes['theta'] = region.rotation\n",
    "        elif region.shape == RegionShape.POINT:\n",
    "            region_shape_attributes['cx'] = c_x\n",
    "            region_shape_attributes['cy'] = c_y\n",
    "        elif region.shape == RegionShape.POLYGON:\n",
    "            region_shape_attributes['all_points_x'] = region.points_x\n",
    "            region_shape_attributes['all_points_y'] = region.points_y\n",
    "        elif region.shape == RegionShape.RECTANGLE:\n",
    "            region_shape_attributes['x'] = region.points_x[0]\n",
    "            region_shape_attributes['y'] = region.points_y[0]\n",
    "            region_shape_attributes['width'] = region.points_x[1] - region.points_x[0]\n",
    "            region_shape_attributes['height'] = region.points_y[1] - region.points_y[0]\n",
    "        return region_shape_attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(VIAAnnotationAdapter.list_files)\n",
    "show_doc(VIAAnnotationAdapter.read_annotations)\n",
    "show_doc(VIAAnnotationAdapter.read_categories)\n",
    "show_doc(VIAAnnotationAdapter.write_files)\n",
    "show_doc(VIAAnnotationAdapter.write_annotations)\n",
    "show_doc(VIAAnnotationAdapter.write_categories)\n",
    "show_doc(VIAAnnotationAdapter.argparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted annotation-core.ipynb.\n",
      "Converted annotation-folder_category_adapter.ipynb.\n",
      "Converted annotation-multi_category_adapter.ipynb.\n",
      "Converted annotation-via_adapter.ipynb.\n",
      "Converted annotation-yolo_adapter.ipynb.\n",
      "Converted annotation_converter.ipynb.\n",
      "Converted annotation_viewer.ipynb.\n",
      "Converted category_tools.ipynb.\n",
      "Converted core.ipynb.\n",
      "Converted dataset-core.ipynb.\n",
      "Converted dataset-image_classification.ipynb.\n",
      "Converted dataset-image_object_detection.ipynb.\n",
      "Converted dataset-image_segmentation.ipynb.\n",
      "Converted dataset-type.ipynb.\n",
      "Converted dataset_generator.ipynb.\n",
      "Converted evaluation-core.ipynb.\n",
      "Converted geometry.ipynb.\n",
      "Converted image-color_palette.ipynb.\n",
      "Converted image-inference.ipynb.\n",
      "Converted image-opencv_tools.ipynb.\n",
      "Converted image-pillow_tools.ipynb.\n",
      "Converted image-tools.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted io-core.ipynb.\n",
      "Converted tensorflow-tflite_converter.ipynb.\n",
      "Converted tensorflow-tflite_metadata.ipynb.\n",
      "Converted tensorflow-tfrecord_builder.ipynb.\n",
      "Converted tools-check_double_images.ipynb.\n",
      "Converted tools-downloader.ipynb.\n",
      "Converted tools-image_size_calculator.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "# for generating scripts from notebook directly\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML-Core]",
   "language": "python",
   "name": "conda-env-ML-Core-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
