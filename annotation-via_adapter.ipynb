{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp annotation.via_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import json\n",
    "import csv\n",
    "import shutil\n",
    "import logging\n",
    "from os.path import join, splitext, getsize, basename, isfile\n",
    "from aiforce.core import assign_arg_prefix\n",
    "from aiforce.annotation.core import Annotation, AnnotationAdapter, Region, RegionShape, parse_region_shape, SubsetType\n",
    "from aiforce.io.core import create_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "DEFAULT_ANNOTATIONS_FILE = 'via_region_data.json'\n",
    "DEFAULT_CATEGORY_LABEL_KEY = 'category'\n",
    "CSV_FIELDNAMES = ['#filename', 'file_size', 'file_attributes', 'region_count', 'region_id', 'region_shape_attributes',\n",
    "                  'region_attributes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIA Annotation Adapter\n",
    "> VIA annotation adapter. To use the VIA annotation tool, refer to the [Homepage](http://www.robots.ox.ac.uk/~vgg/software/via/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current supported annotations:\n",
    "- circle\n",
    "- ellipse\n",
    "- point\n",
    "- polyline\n",
    "- rectangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current supported annotation tool versions:\n",
    "- [VIA version 1 (v1.0.6)](https://www.robots.ox.ac.uk/~vgg/software/via/via-1.0.6.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adapter has the following parameters:\n",
    "- `--path`: the path to the base folder containing the annotations (e.g.: *data/image_object_detection/my_collection*)\n",
    "- `--categories_file_name`: tThe path to the categories file if not set, default to *categories.txt*\n",
    "- `--annotations_file_name`: The name of annotations file. if not set, default to *via_region_data.json*\n",
    "- `--category_label_key`: The key, the category label key is stored in the annotation file, default to *category*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class VIAAnnotationAdapter(AnnotationAdapter):\n",
    "    \"\"\"\n",
    "    Adapter to read and write annotations in the VIA annotation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path, categories_file_name=None, annotations_file_name=None, category_label_key=None):\n",
    "        \"\"\"\n",
    "        VIA Adapter to read and write annotations.\n",
    "        `path`: the folder containing the annotations\n",
    "        `categories_file_name`: the name of the categories file\n",
    "        `annotations_file_name`: the name of annotations file\n",
    "        `category_label_key`: the key of the category label\n",
    "        \"\"\"\n",
    "        super().__init__(path, categories_file_name)\n",
    "        if annotations_file_name is None:\n",
    "            self.annotations_file_name = DEFAULT_ANNOTATIONS_FILE\n",
    "        else:\n",
    "            self.annotations_file_name = annotations_file_name\n",
    "\n",
    "        if category_label_key is None:\n",
    "            self.category_label_key = DEFAULT_CATEGORY_LABEL_KEY\n",
    "        else:\n",
    "            self.category_label_key = category_label_key\n",
    "\n",
    "    @classmethod\n",
    "    def argparse(cls, prefix=None):\n",
    "        \"\"\"\n",
    "        Returns the argument parser containing argument definition for command line use.\n",
    "        `prefix`: a parameter prefix to set, if needed\n",
    "        return: the argument parser\n",
    "        \"\"\"\n",
    "        parser = super(VIAAnnotationAdapter, cls).argparse(prefix=prefix)\n",
    "        parser.add_argument(assign_arg_prefix('--annotations_file_name', prefix),\n",
    "                            dest=\"annotations_file_name\",\n",
    "                            help=\"The name of annotations file.\",\n",
    "                            default=None)\n",
    "        parser.add_argument(assign_arg_prefix('--category_label_key', prefix),\n",
    "                            dest=\"category_label_key\",\n",
    "                            help=\"The key of the category label.\",\n",
    "                            default=None)\n",
    "\n",
    "        return parser\n",
    "\n",
    "    def read_annotations(self, subset_type=SubsetType.TRAINVAL):\n",
    "        \"\"\"\n",
    "        Reads a VIA annotations file.\n",
    "        Supports JSON and CSV file format.\n",
    "        Format is inferred from the annotations_file setting.\n",
    "        `subset_type`: the subset type to read\n",
    "        return: the annotations as dictionary\n",
    "        \"\"\"\n",
    "        path = join(self.path, str(subset_type))\n",
    "        annotations_file_name = self._annotation_file_name_suffix_handling(subset_type)\n",
    "        annotations_file_path = join(self.path, annotations_file_name)\n",
    "        logger.info('Read file sources from {}'.format(path))\n",
    "        logger.info('Read annotations from {}'.format(annotations_file_path))\n",
    "        return self._read_annotations_v1(path, annotations_file_path)\n",
    "\n",
    "    def _read_annotations_v1(self, path, annotations_file_path):\n",
    "        \"\"\"\n",
    "        Reads a VIA v1 annotations file.\n",
    "        Supports JSON and CSV file format.\n",
    "        `path`: the path to read file sources from\n",
    "        `annotation_file_path`: the path to the annotations file\n",
    "        return: the annotations as dictionary\n",
    "        \"\"\"\n",
    "        file_extension = splitext(annotations_file_path)[1]\n",
    "\n",
    "        if file_extension.lower() == '.json':\n",
    "            logger.info('Read VIA v1 annotations in JSON format')\n",
    "            annotations = self._read_annotations_v1_json(path, annotations_file_path)\n",
    "        elif file_extension.lower() == '.csv':\n",
    "            logger.info('Read VIA v1 annotations in CSV format')\n",
    "            annotations = self._read_annotations_v1_csv(path, annotations_file_path)\n",
    "        else:\n",
    "            message = 'Unsupported annotation format at {}'.format(annotations_file_path)\n",
    "            logger.error(message)\n",
    "            raise ValueError(message)\n",
    "\n",
    "        return annotations\n",
    "\n",
    "    def _read_annotations_v1_csv(self, path, annotations_file_path):\n",
    "        \"\"\"\n",
    "        Reads a VIA v1 CSV annotations file.\n",
    "        `path`: the path to read file sources from\n",
    "        `annotation_file_path`: the path to the annotations file\n",
    "        return: the annotations as dictionary\n",
    "        \"\"\"\n",
    "        annotations = {}\n",
    "\n",
    "        with open(annotations_file_path, newline='') as csv_file:\n",
    "            reader = csv.DictReader(csv_file)\n",
    "\n",
    "            skipped_annotations = []\n",
    "            for row in reader:\n",
    "                file_path = join(path, row['#filename'])\n",
    "                if not isfile(file_path):\n",
    "                    logger.warning(\"{}: Source file not found, skip annotation.\".format(file_path))\n",
    "                    skipped_annotations.append(file_path)\n",
    "                    continue\n",
    "\n",
    "                annotation_id = \"{}{}\".format(row['#filename'], row['file_size'])\n",
    "\n",
    "                if annotation_id not in annotations:\n",
    "                    annotations[annotation_id] = Annotation(annotation_id=annotation_id, file_path=file_path)\n",
    "\n",
    "                annotation = annotations[annotation_id]\n",
    "\n",
    "                region_shape_attributes = json.loads(row['region_shape_attributes'])\n",
    "                region = self._parse_region_shape_attributes(region_shape_attributes)\n",
    "                region_attributes = json.loads(row['region_attributes'])\n",
    "                category = None\n",
    "                if region_attributes and self.category_label_key in region_attributes:\n",
    "                    category = region_attributes[self.category_label_key]\n",
    "                region.labels = [category] if category else []\n",
    "                annotation.regions.append(region)\n",
    "\n",
    "        logger.info('Finished read annotations')\n",
    "        logger.info('Annotations read: {}'.format(len(annotations)))\n",
    "        if skipped_annotations:\n",
    "            logger.info('Annotations skipped: {}'.format(len(skipped_annotations)))\n",
    "\n",
    "        return annotations\n",
    "\n",
    "    def _read_annotations_v1_json(self, path, annotations_file_path):\n",
    "        \"\"\"\n",
    "        Reads a VIA v1 JSON annotations file.\n",
    "        `path`: the path to read file sources from\n",
    "        `annotation_file_path`: the path to the annotations file\n",
    "        return: the annotations as dictionary\n",
    "        \"\"\"\n",
    "        annotations = {}\n",
    "\n",
    "        with open(annotations_file_path) as json_file:\n",
    "            via_annotations = json.load(json_file)\n",
    "\n",
    "            skipped_annotations = []\n",
    "            for data in via_annotations.values():\n",
    "                file_path = join(path, data['filename'])\n",
    "                if not isfile(file_path):\n",
    "                    logger.warning(\"{}: Source file not found, skip annotation.\".format(file_path))\n",
    "                    skipped_annotations.append(file_path)\n",
    "                    continue\n",
    "\n",
    "                annotation_id = \"{}{}\".format(data['filename'], data['size'])\n",
    "\n",
    "                if annotation_id not in annotations:\n",
    "                    annotations[annotation_id] = Annotation(annotation_id=annotation_id, file_path=file_path)\n",
    "\n",
    "                annotation = annotations[annotation_id]\n",
    "\n",
    "                for region_data in data['regions'].values():\n",
    "                    region_shape_attributes = region_data['shape_attributes']\n",
    "                    region = self._parse_region_shape_attributes(region_shape_attributes)\n",
    "                    region_attributes = region_data['region_attributes']\n",
    "                    category = None\n",
    "                    if region_attributes and self.category_label_key in region_attributes:\n",
    "                        category = region_attributes[self.category_label_key]\n",
    "                    region.labels = [category] if category else []\n",
    "                    annotation.regions.append(region)\n",
    "\n",
    "        logger.info('Finished read annotations')\n",
    "        logger.info('Annotations read: {}'.format(len(annotations)))\n",
    "        if skipped_annotations:\n",
    "            logger.info('Annotations skipped: {}'.format(len(skipped_annotations)))\n",
    "\n",
    "        return annotations\n",
    "\n",
    "    def write_annotations(self, annotations, subset_type=SubsetType.TRAINVAL):\n",
    "        \"\"\"\n",
    "        Writes a VIA annotations file and copy the corresponding source files.\n",
    "        Supports JSON and CSV file format.\n",
    "        Format is inferred from the annotations_file setting.\n",
    "        `annotations`: the annotations as dictionary\n",
    "        `subset_type`: the subset type to write\n",
    "        return: a list of written target file paths\n",
    "        \"\"\"\n",
    "        path = join(self.path, str(subset_type))\n",
    "        target_folder = create_folder(path)\n",
    "        annotations_file_name = self._annotation_file_name_suffix_handling(subset_type)\n",
    "        annotations_file_path = join(self.path, annotations_file_name)\n",
    "        logger.info('Write file sources to {}'.format(target_folder))\n",
    "        logger.info('Write annotations to {}'.format(annotations_file_path))\n",
    "\n",
    "        return self._write_annotations_v1(path, annotations_file_path, annotations)\n",
    "\n",
    "    def _write_annotations_v1(self, path, annotations_file_path, annotations):\n",
    "        \"\"\"\n",
    "        Writes a VIA v1 annotations file and copy the corresponding source files.\n",
    "        Supports JSON and CSV file format.\n",
    "        `path`: the path to write file sources into\n",
    "        `annotation_file_path`: the path to the annotations file\n",
    "        `annotations`: the annotations to write\n",
    "        return: a list of written source file paths\n",
    "        \"\"\"\n",
    "        file_extension = splitext(annotations_file_path)[1]\n",
    "\n",
    "        if file_extension.lower() == '.json':\n",
    "            logger.info('Write VIA v1 annotations in JSON format')\n",
    "            copied_files = self._write_annotations_v1_json(path, annotations_file_path, annotations)\n",
    "        elif file_extension.lower() == '.csv':\n",
    "            logger.info('Write VIA v1 annotations in CSV format')\n",
    "            copied_files = self._write_annotations_v1_csv(path, annotations_file_path, annotations)\n",
    "        else:\n",
    "            message = 'Unsupported annotation format at {}'.format(annotations_file_path)\n",
    "            logger.error(message)\n",
    "            raise ValueError(message)\n",
    "        return copied_files\n",
    "\n",
    "    def _write_annotations_v1_csv(self, path, annotations_file_path, annotations):\n",
    "        \"\"\"\n",
    "        Writes a VIA v1 CSV annotations file and copy the corresponding source files.\n",
    "        `path`: the path to write file sources into\n",
    "        `annotation_file_path`: the path to the annotations file\n",
    "        `annotations`: the annotations to write\n",
    "        return: a list of written source file paths\n",
    "        \"\"\"\n",
    "        with open(annotations_file_path, 'w', newline='') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=CSV_FIELDNAMES)\n",
    "            writer.writeheader()\n",
    "\n",
    "            skipped_annotations = []\n",
    "            copied_files = []\n",
    "            for annotation in annotations.values():\n",
    "                target_file = join(path, basename(annotation.file_path))\n",
    "\n",
    "                if not isfile(annotation.file_path):\n",
    "                    logger.warning(\"{}: Source file not found, skip annotation.\".format(annotation.file_path))\n",
    "                    skipped_annotations.append(annotation.file_path)\n",
    "                    continue\n",
    "                if isfile(target_file):\n",
    "                    logger.warning(\"{}: Target file already exist, skip annotation.\".format(annotation.file_path))\n",
    "                    skipped_annotations.append(annotation.file_path)\n",
    "                    continue\n",
    "\n",
    "                file_size = getsize(annotation.file_path)\n",
    "                file_name = basename(annotation.file_path)\n",
    "                for index, region in enumerate(annotation.regions):\n",
    "                    region_shape_attributes = self._create_region_shape_attributes(region)\n",
    "                    region_attributes = {\n",
    "                        self.category_label_key: ' '.join(region.labels) if len(region.labels) else ''\n",
    "                    }\n",
    "\n",
    "                    writer.writerow({'#filename': file_name,\n",
    "                                     'file_size': file_size,\n",
    "                                     'file_attributes': '{}',\n",
    "                                     'region_count': len(annotation.regions),\n",
    "                                     'region_id': str(index),\n",
    "                                     'region_shape_attributes': json.dumps(region_shape_attributes),\n",
    "                                     'region_attributes': json.dumps(region_attributes)})\n",
    "                # copy the file\n",
    "                shutil.copy2(annotation.file_path, target_file)\n",
    "                copied_files.append(target_file)\n",
    "\n",
    "        logger.info('Finished write annotations')\n",
    "        logger.info('Annotations written: {}'.format(len(annotations) - len(skipped_annotations)))\n",
    "        if skipped_annotations:\n",
    "            logger.info('Annotations skipped: {}'.format(len(skipped_annotations)))\n",
    "        return copied_files\n",
    "\n",
    "    def _write_annotations_v1_json(self, path, annotations_file_path, annotations):\n",
    "        \"\"\"\n",
    "        Writes a VIA v1 JSON annotations file and copy the corresponding source files.\n",
    "        `path`: the path to write file sources into\n",
    "        `annotation_file_path`: the path to the annotations file\n",
    "        `annotations`: the annotations to write\n",
    "        return: a list of written source file paths\n",
    "        \"\"\"\n",
    "        json_annotations = {}\n",
    "        skipped_annotations = []\n",
    "        copied_files = []\n",
    "\n",
    "        for annotation in annotations.values():\n",
    "            target_file = join(path, basename(annotation.file_path))\n",
    "\n",
    "            if not isfile(annotation.file_path):\n",
    "                logger.warning(\"{}: Source file not found, skip annotation.\".format(annotation.file_path))\n",
    "                skipped_annotations.append(annotation.file_path)\n",
    "                continue\n",
    "            if isfile(target_file):\n",
    "                logger.warning(\"{}: Target file already exist, skip annotation.\".format(annotation.file_path))\n",
    "                skipped_annotations.append(annotation.file_path)\n",
    "                continue\n",
    "\n",
    "            file_size = getsize(annotation.file_path)\n",
    "            file_name = basename(annotation.file_path)\n",
    "            file_id = '{:s}{:d}'.format(file_name, file_size)\n",
    "            regions = {}\n",
    "            for index, region in enumerate(annotation.regions):\n",
    "                regions[str(index)] = {\n",
    "                    'shape_attributes': self._create_region_shape_attributes(region),\n",
    "                    'region_attributes': {\n",
    "                        self.category_label_key: ' '.join(region.labels) if len(region.labels) else ''\n",
    "                    }\n",
    "                }\n",
    "            json_annotations[file_id] = {\n",
    "                'fileref': \"\",\n",
    "                'size': file_size,\n",
    "                'filename': file_name,\n",
    "                'base64_img_data': \"\",\n",
    "                'file_attributes': '{}',\n",
    "                \"regions\": regions\n",
    "            }\n",
    "            # copy the file\n",
    "            shutil.copy2(annotation.file_path, target_file)\n",
    "            copied_files.append(target_file)\n",
    "\n",
    "        with open(annotations_file_path, 'w') as json_file:\n",
    "            json.dump(json_annotations, json_file)\n",
    "\n",
    "        logger.info('Finished write annotations')\n",
    "        logger.info('Annotations written: {}'.format(len(annotations) - len(skipped_annotations)))\n",
    "        if skipped_annotations:\n",
    "            logger.info('Annotations skipped: {}'.format(len(skipped_annotations)))\n",
    "        return copied_files\n",
    "\n",
    "    def _annotation_file_name_suffix_handling(self, subset_type):\n",
    "        \"\"\"\n",
    "        Handle annotations file name based on the subset type.\n",
    "        `subset_type`: the subset type to handle\n",
    "        return: the annotations file name\n",
    "        \"\"\"\n",
    "        file_name, ext = splitext(self.annotations_file_name)\n",
    "        if subset_type in [SubsetType.TRAIN, SubsetType.VAL] and not file_name.endswith(str(subset_type)):\n",
    "            suffix = \"_{}\".format(str(subset_type))\n",
    "            return \"{}{}{}\".format(file_name, suffix, ext)\n",
    "        return self.annotations_file_name\n",
    "\n",
    "    @classmethod\n",
    "    def _parse_region_shape_attributes(cls, region_shape_attributes):\n",
    "        \"\"\"\n",
    "        Parse region shape attributes.\n",
    "        `region_shape_attributes`: the region shape attributes as dictionary\n",
    "        return: the corresponding annotation\n",
    "        \"\"\"\n",
    "        if not region_shape_attributes:\n",
    "            return Annotation()\n",
    "\n",
    "        region_shape = parse_region_shape(region_shape_attributes['name'])\n",
    "        points_x = None\n",
    "        points_y = None\n",
    "        radius_x = 0\n",
    "        radius_y = 0\n",
    "        if region_shape == RegionShape.CIRCLE:\n",
    "            points_x = [region_shape_attributes['cx']]\n",
    "            points_y = [region_shape_attributes['cy']]\n",
    "            radius_x = region_shape_attributes['r']\n",
    "            radius_y = region_shape_attributes['r']\n",
    "        elif region_shape == RegionShape.ELLIPSE:\n",
    "            points_x = [region_shape_attributes['cx']]\n",
    "            points_y = [region_shape_attributes['cy']]\n",
    "            radius_x = region_shape_attributes['rx']\n",
    "            radius_y = region_shape_attributes['ry']\n",
    "        elif region_shape == RegionShape.POINT:\n",
    "            points_x = [region_shape_attributes['cx']]\n",
    "            points_y = [region_shape_attributes['cy']]\n",
    "        elif region_shape == RegionShape.POLYGON:\n",
    "            points_x = region_shape_attributes['all_points_x']\n",
    "            points_y = region_shape_attributes['all_points_y']\n",
    "        elif region_shape == RegionShape.RECTANGLE:\n",
    "            x = region_shape_attributes['x']\n",
    "            y = region_shape_attributes['y']\n",
    "            width = region_shape_attributes['width']\n",
    "            height = region_shape_attributes['height']\n",
    "            points_x = [x, x + width]\n",
    "            points_y = [y, y + height]\n",
    "        return Region(shape=region_shape, points_x=points_x, points_y=points_y, radius_x=radius_x, radius_y=radius_y)\n",
    "\n",
    "    @classmethod\n",
    "    def _create_region_shape_attributes(cls, region: Region):\n",
    "        \"\"\"\n",
    "        Create region shape attributes.\n",
    "        `region`: the region to create region shape attributes from\n",
    "        return: the corresponding region shape attributes as dictionary\n",
    "        \"\"\"\n",
    "        region_shape_attributes = {\n",
    "            \"name\": str(region.shape),\n",
    "\n",
    "        }\n",
    "        c_x = region.points_x[0] if len(region.points_x) else 0\n",
    "        c_y = region.points_y[0] if len(region.points_y) else 0\n",
    "\n",
    "        if region.shape == RegionShape.CIRCLE:\n",
    "            region_shape_attributes['cx'] = c_x\n",
    "            region_shape_attributes['cy'] = c_y\n",
    "            region_shape_attributes['r'] = max(region.radius_x, region.radius_y)\n",
    "        elif region.shape == RegionShape.ELLIPSE:\n",
    "            region_shape_attributes['cx'] = c_x\n",
    "            region_shape_attributes['cy'] = c_y\n",
    "            region_shape_attributes['rx'] = region.radius_x\n",
    "            region_shape_attributes['ry'] = region.radius_y\n",
    "        elif region.shape == RegionShape.POINT:\n",
    "            region_shape_attributes['cx'] = c_x\n",
    "            region_shape_attributes['cy'] = c_y\n",
    "        elif region.shape == RegionShape.POLYGON:\n",
    "            region_shape_attributes['all_points_x'] = region.points_x\n",
    "            region_shape_attributes['all_points_y'] = region.points_y\n",
    "        elif region.shape == RegionShape.RECTANGLE:\n",
    "            region_shape_attributes['x'] = region.points_x[0]\n",
    "            region_shape_attributes['y'] = region.points_y[0]\n",
    "            region_shape_attributes['width'] = region.points_x[1] - region.points_x[0]\n",
    "            region_shape_attributes['height'] = region.points_y[1] - region.points_y[0]\n",
    "        return region_shape_attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(VIAAnnotationAdapter.list_files)\n",
    "show_doc(VIAAnnotationAdapter.read_annotations)\n",
    "show_doc(VIAAnnotationAdapter.read_categories)\n",
    "show_doc(VIAAnnotationAdapter.write_files)\n",
    "show_doc(VIAAnnotationAdapter.write_annotations)\n",
    "show_doc(VIAAnnotationAdapter.write_categories)\n",
    "show_doc(VIAAnnotationAdapter.argparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted annotation-core.ipynb.\n",
      "Converted annotation-folder_category_adapter.ipynb.\n",
      "Converted annotation-multi_category_adapter.ipynb.\n",
      "Converted annotation-via_adapter.ipynb.\n",
      "Converted annotation-yolo_adapter.ipynb.\n",
      "Converted annotation_converter.ipynb.\n",
      "Converted annotation_viewer.ipynb.\n",
      "Converted category_tools.ipynb.\n",
      "Converted core.ipynb.\n",
      "Converted dataset-core.ipynb.\n",
      "Converted dataset-image_classification.ipynb.\n",
      "Converted dataset-image_object_detection.ipynb.\n",
      "Converted dataset-image_segmentation.ipynb.\n",
      "Converted dataset-type.ipynb.\n",
      "Converted dataset_generator.ipynb.\n",
      "Converted evaluation-core.ipynb.\n",
      "Converted geometry.ipynb.\n",
      "Converted image-color_palette.ipynb.\n",
      "Converted image-inference.ipynb.\n",
      "Converted image-opencv_tools.ipynb.\n",
      "Converted image-pillow_tools.ipynb.\n",
      "Converted image-tools.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted io-core.ipynb.\n",
      "Converted tensorflow-tflite_converter.ipynb.\n",
      "Converted tensorflow-tflite_metadata.ipynb.\n",
      "Converted tensorflow-tfrecord_builder.ipynb.\n",
      "Converted tools-check_double_images.ipynb.\n",
      "Converted tools-downloader.ipynb.\n",
      "Converted tools-image_size_calculator.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "# for generating scripts from notebook directly\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML-Core]",
   "language": "python",
   "name": "conda-env-ML-Core-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
