{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp annotation.yolo_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.export import notebook2script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import csv\n",
    "import sys\n",
    "import argparse\n",
    "import logging\n",
    "from os.path import join, splitext, basename, dirname, isfile\n",
    "from mlcore.category_tools import read_categories\n",
    "from mlcore.io.core import scan_files, create_folder\n",
    "from mlcore.image.pillow_tools import get_image_size\n",
    "from mlcore.annotation.core import Annotation, AnnotationAdapter, Region, RegionShape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "FIELD_NAMES = ['class_number', 'c_x', 'c_y', 'width', 'height']\n",
    "DEFAULT_CATEGORIES_FILE = 'categories.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Annotation Adapter\n",
    "> YOLO annotation adapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This adapter is tested with the [YOLOv3 Pytorch](https://github.com/ultralytics/yolov3) and [YOLOv5 Pytorch](https://github.com/ultralytics/yolov5) repositories.\n",
    "Bounding boxes are normalized between [0,1].\n",
    "Images should be in a separate folder (named e.g. *images/*).\n",
    "Annotations should be in a separate folder (named e.g. *labels/*) and must have the same file name as corresponding image source file with the ending *.txt*. Below is an example structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "categories.txt\n",
    "images/\n",
    "    image1.jpg\n",
    "labels/\n",
    "    image1.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `args` parameter contains the following options:\n",
    "- `files_path`: the path to the folder containing the source files (e.g.: *data/image_object_detection/my_collection/trainval/images*)\n",
    "- `annotations_path`: The path to the multi classification CSV annotation file (e.g.: data/image_object_detection/my_collection/trainval/labels)\n",
    "- `categories_file`: The path to the categories file. If not explicitly set try to infer the file *categories.txt* from files_path (e.g.: data/image_object_detection/my_collection/categories.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class YOLOAdapter(AnnotationAdapter):\n",
    "    \"\"\"\n",
    "    Adapter to read and write annotations in the YOLO format.\n",
    "    `args`: the arguments containing the parameters\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.files_path = args.files_path\n",
    "        self.annotations_path = args.annotations_path\n",
    "        if args.categories_file is None:\n",
    "            self.categories_file = join(dirname(dirname(self.files_path)), DEFAULT_CATEGORIES_FILE)\n",
    "        else:\n",
    "            self.categories_file = args.categories_file\n",
    "\n",
    "    def read(self):\n",
    "        \"\"\"\n",
    "        Reads YOLO annotations from the annotations folder.\n",
    "        return: the annotations as dictionary\n",
    "        \"\"\"\n",
    "        annotations = {}\n",
    "        logger.info('Read annotations from {}'.format(self.annotations_path))\n",
    "\n",
    "        annotation_files = scan_files(self.annotations_path, file_extensions='.txt')\n",
    "        categories = read_categories(self.categories_file)\n",
    "        categories_len = len(categories)\n",
    "        skipped_annotations = []\n",
    "\n",
    "        for annotation_file in annotation_files:\n",
    "            with open(annotation_file, newline='') as csv_file:\n",
    "                annotation_file_name = basename(annotation_file)\n",
    "                file_name, _ = splitext(annotation_file_name)\n",
    "                file_path = join(self.files_path, '{}{}'.format(file_name, '.jpg'))\n",
    "\n",
    "                if not isfile(file_path):\n",
    "                    logger.warning(\"{}: Source file not found, skip annotation.\".format(file_path))\n",
    "                    skipped_annotations.append(file_path)\n",
    "                    continue\n",
    "\n",
    "                if annotation_file not in annotations:\n",
    "                    annotations[annotation_file] = Annotation(annotation_id=annotation_file, file_path=file_path)\n",
    "\n",
    "                annotation = annotations[annotation_file]\n",
    "\n",
    "                reader = csv.DictReader(csv_file, fieldnames=FIELD_NAMES, delimiter=' ')\n",
    "                _, image_width, image_height = get_image_size(file_path)\n",
    "                for row in reader:\n",
    "                    c_x = float(row[\"c_x\"])\n",
    "                    c_y = float(row[\"c_y\"])\n",
    "                    width = float(row[\"width\"])\n",
    "                    height = float(row[\"height\"])\n",
    "                    class_number = int(row[\"class_number\"])\n",
    "                    # denormalize bounding box\n",
    "                    x_min = _denormalize_value(c_x - (width / 2), image_width)\n",
    "                    y_min = _denormalize_value(c_y - (height / 2), image_height)\n",
    "                    x_max = x_min + _denormalize_value(width, image_width)\n",
    "                    y_max = y_min + _denormalize_value(height, image_height)\n",
    "                    points_x = [x_min, x_max]\n",
    "                    points_y = [y_min, y_max]\n",
    "\n",
    "                    labels = [categories[class_number]] if class_number < categories_len else []\n",
    "                    if not labels:\n",
    "                        logger.warning(\"{}: Class number exceeds categories, set label as empty.\".format(\n",
    "                            annotation_file\n",
    "                        ))\n",
    "                    region = Region(shape=RegionShape.RECTANGLE, points_x=points_x, points_y=points_y, labels=labels)\n",
    "                    annotation.regions.append(region)\n",
    "\n",
    "        logger.info('Finished read annotations')\n",
    "        logger.info('Annotations read: {}'.format(len(annotations)))\n",
    "        if skipped_annotations:\n",
    "            logger.info('Annotations skipped: {}'.format(len(skipped_annotations)))\n",
    "\n",
    "        return annotations\n",
    "\n",
    "    def write(self, annotations):\n",
    "        \"\"\"\n",
    "        Writes YOLO annotations to the annotations folder and copy the corresponding source files.\n",
    "        `annotations`: the annotations to write\n",
    "        \"\"\"\n",
    "        annotations_folder = create_folder(self.annotations_path)\n",
    "        target_folder = create_folder(self.files_path)\n",
    "        categories = read_categories(self.categories_file)\n",
    "\n",
    "        logger.info('Write annotations to {}'.format(annotations_folder))\n",
    "        logger.info('Write file sources to {}'.format(target_folder))\n",
    "\n",
    "        skipped_annotations = []\n",
    "\n",
    "        for annotation in annotations.values():\n",
    "            file_name, _ = splitext(basename(annotation.file_path))\n",
    "            annotations_file = join(annotations_folder, '{}{}'.format(file_name, '.txt'))\n",
    "            target_file = join(target_folder, basename(annotation.file_path))\n",
    "\n",
    "            if not isfile(annotation.file_path):\n",
    "                logger.warning(\"{}: Source file not found, skip annotation.\".format(annotation.file_path))\n",
    "                skipped_annotations.append(annotation.file_path)\n",
    "                continue\n",
    "            if isfile(target_file):\n",
    "                logger.warning(\"{}: Target file already exist, skip annotation.\".format(annotation.file_path))\n",
    "                skipped_annotations.append(annotation.file_path)\n",
    "                continue\n",
    "\n",
    "            _, image_width, image_height = get_image_size(annotation.file_path)\n",
    "            with open(annotations_file, 'w', newline='') as csv_file:\n",
    "                writer = csv.DictWriter(csv_file, fieldnames=FIELD_NAMES, delimiter=' ')\n",
    "\n",
    "                skipped_regions = []\n",
    "                for index, region in enumerate(annotation.regions):\n",
    "                    if region.shape != RegionShape.RECTANGLE:\n",
    "                        logger.warning('Unsupported shape {}, skip region {} at path: {}'.format(region.shape,\n",
    "                                                                                                 index,\n",
    "                                                                                                 annotations_file))\n",
    "                        skipped_regions.append(region)\n",
    "                        continue\n",
    "\n",
    "                    x_min, x_max = region.points_x\n",
    "                    y_min, y_max = region.points_y\n",
    "                    width = x_max - x_min\n",
    "                    height = y_max - y_min\n",
    "                    # normalize bounding box\n",
    "                    c_x = _normalize_value(x_min + width / 2, image_width)\n",
    "                    c_y = _normalize_value(y_min + height / 2, image_height)\n",
    "                    width = _normalize_value(width, image_width)\n",
    "                    height = _normalize_value(height, image_height)\n",
    "                    label = region.labels[0] if len(region.labels) else ''\n",
    "                    try:\n",
    "                        class_number = categories.index(label)\n",
    "                    except ValueError:\n",
    "                        logger.warning('Unsupported label {}, skip region {} at path: {}'.format(label,\n",
    "                                                                                                 index,\n",
    "                                                                                                 annotations_file))\n",
    "                        skipped_regions.append(region)\n",
    "                        continue\n",
    "\n",
    "                    writer.writerow(dict(zip(FIELD_NAMES, [class_number, c_x, c_y, width, height])))\n",
    "\n",
    "                if len(skipped_regions) == len(annotation.regions):\n",
    "                    logger.warning(\"{}: All regions skipped, skip annotation.\".format(annotation.file_path))\n",
    "                    skipped_annotations.append(annotation.file_path)\n",
    "\n",
    "        logger.info('Finished write annotations')\n",
    "        logger.info('Annotations written: {}'.format(len(annotations) - len(skipped_annotations)))\n",
    "        if skipped_annotations:\n",
    "            logger.info('Annotations skipped: {}'.format(len(skipped_annotations)))\n",
    "\n",
    "    @classmethod\n",
    "    def argparse(cls, prefix=None):\n",
    "        \"\"\"\n",
    "        Returns the argument parser containing argument definition for command line use.\n",
    "        `prefix`: a parameter prefix to set, if needed\n",
    "        return: the argument parser\n",
    "        \"\"\"\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(cls.assign_prefix('--files_path', prefix),\n",
    "                            dest=\"files_path\",\n",
    "                            help=\"The path to the folder containing the files.\",\n",
    "                            required=True)\n",
    "        parser.add_argument(cls.assign_prefix('--annotations_file', prefix),\n",
    "                            dest=\"annotations_path\",\n",
    "                            help=\"The path to the folder containing the annotations.\",\n",
    "                            required=True)\n",
    "        parser.add_argument(cls.assign_prefix('--categories_file', prefix),\n",
    "                            dest=\"categories_file\",\n",
    "                            help=\"The path to the categories file. If not explicitly set try to infer from files_path.\",\n",
    "                            default=None)\n",
    "        return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(YOLOAdapter.read)\n",
    "show_doc(YOLOAdapter.write)\n",
    "show_doc(YOLOAdapter.argparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def _denormalize_value(value, metric):\n",
    "    \"\"\"\n",
    "    Denormalize a bounding box value\n",
    "    `value`: the value to denormalize\n",
    "    `metric`: the metric to denormalize from\n",
    "    return: the denormalized value\n",
    "    \"\"\"\n",
    "    return int(value * metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def _normalize_value(value, metric):\n",
    "    \"\"\"\n",
    "    Normalize a bounding box value\n",
    "    `value`: the value to normalize\n",
    "    `metric`: the metric to normalize against\n",
    "    return: the normalized value\n",
    "    \"\"\"\n",
    "    return float(value) / metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def configure_logging(logging_level=logging.INFO):\n",
    "    \"\"\"\n",
    "    Configures logging for the system.\n",
    "\n",
    "    :param logging_level: The logging level to use.\n",
    "    \"\"\"\n",
    "    logger.setLevel(logging_level)\n",
    "\n",
    "    handler = logging.StreamHandler(sys.stdout)\n",
    "    handler.setLevel(logging_level)\n",
    "\n",
    "    logger.addHandler(handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted annotation-core.ipynb.\n",
      "Converted annotation-folder_category_adapter.ipynb.\n",
      "Converted annotation-multi_category_adapter.ipynb.\n",
      "Converted annotation-via_adapter.ipynb.\n",
      "Converted annotation-viewer.ipynb.\n",
      "Converted annotation-yolo_adapter.ipynb.\n",
      "Converted category_tools.ipynb.\n",
      "Converted core.ipynb.\n",
      "Converted dataset-core.ipynb.\n",
      "Converted dataset-image_classification.ipynb.\n",
      "Converted dataset-image_object_detection.ipynb.\n",
      "Converted dataset-image_segmentation.ipynb.\n",
      "Converted dataset-type.ipynb.\n",
      "Converted dataset_generator.ipynb.\n",
      "Converted evaluation-core.ipynb.\n",
      "Converted geometry.ipynb.\n",
      "Converted image-color_palette.ipynb.\n",
      "Converted image-inference.ipynb.\n",
      "Converted image-opencv_tools.ipynb.\n",
      "Converted image-pillow_tools.ipynb.\n",
      "Converted image-tools.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted io-core.ipynb.\n",
      "Converted tensorflow-tflite_converter.ipynb.\n",
      "Converted tensorflow-tflite_metadata.ipynb.\n",
      "Converted tensorflow-tfrecord_builder.ipynb.\n",
      "Converted tools-check_double_images.ipynb.\n",
      "Converted tools-downloader.ipynb.\n",
      "Converted tools-image_size_calculator.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "# for generating scripts from notebook directly\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML-Core]",
   "language": "python",
   "name": "conda-env-ML-Core-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
