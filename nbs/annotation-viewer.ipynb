{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp annotation.viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import logging\n",
    "import cv2\n",
    "import numpy as np\n",
    "from mlcore.image.opencv_tools import fit_to_max_size\n",
    "from mlcore.annotation.core import RegionShape\n",
    "from mlcore.annotation.via_adapter import read_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation Viewer\n",
    "> Annotation Viewer Notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def show_annotated_images(annotations, max_width=0, max_height=0):\n",
    "    \"\"\"\n",
    "    Show images with corresponding annotations.\n",
    "    Images are shown one at a time with switching by using the arrow left/right keys.\n",
    "    `annotations`: The annotations for the images\n",
    "    `max_width`: The maximum width to scale the image for visibility.\n",
    "    `max_height`: The maximum height to scale the image for visibility.\n",
    "    \"\"\"\n",
    "    len_annotations = len(annotations)\n",
    "\n",
    "    if len_annotations == 0:\n",
    "        logger.error(\"No Annotations found\")\n",
    "        return\n",
    "\n",
    "    index = 0\n",
    "    annotation_keys = list(annotations.keys())\n",
    "\n",
    "    logger.info(\"Keys to use:\")\n",
    "    logger.info(\"n = Next Image\")\n",
    "    logger.info(\"b = Previous Image\")\n",
    "    logger.info(\"q = Quit\")\n",
    "\n",
    "    logger.info(\"Annotations to view: {}\".format(len_annotations))\n",
    "\n",
    "    while True:\n",
    "        annotation_id = annotation_keys[index]\n",
    "        annotation = annotations[annotation_id]\n",
    "        logger.info(\"View Image {}/{}: {}\".format(index + 1, len_annotations, annotation.file_path))\n",
    "        img = cv2.imread(annotation.file_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "        if img is None:\n",
    "            logger.info(\"Image not found at {}\".format(annotation.file_path))\n",
    "            img = np.zeros(shape=(1, 1, 3))\n",
    "\n",
    "        if annotation.regions:\n",
    "            logger.info(\"Found {} regions\".format(len(annotation.regions)))\n",
    "            for region_index, region in enumerate(annotation.regions):\n",
    "                points = list(zip(region.points_x, region.points_y))\n",
    "                logger.info(\"Found {} of category {} with {} points: {}\".format(region.shape,\n",
    "                                                                                ','.join(region.labels),\n",
    "                                                                                len(points), points))\n",
    "                if region.shape == RegionShape.CIRCLE:\n",
    "                    img = cv2.circle(img, points[0], region.radius_x, (0, 255, 255), 2)\n",
    "                elif region.shape == RegionShape.ELLIPSE:\n",
    "                    img = cv2.ellipse(img, points[0], (region.radius_x, region.radius_y), 0, 0, 360,\n",
    "                                      (0, 255, 255), 2)\n",
    "                elif region.shape == RegionShape.POINT:\n",
    "                    img = cv2.circle(img, points[0], 1, (0, 255, 255), 2)\n",
    "                elif region.shape == RegionShape.POLYGON:\n",
    "                    pts = np.array(points, np.int32)\n",
    "                    pts = pts.reshape((-1, 1, 2))\n",
    "                    img = cv2.polylines(img, [pts], True, (0, 255, 255), 2)\n",
    "                elif region.shape == RegionShape.RECTANGLE:\n",
    "                    img = cv2.rectangle(img, points[0], points[1], (0, 255, 255), 2)\n",
    "\n",
    "        if max_width and max_height:\n",
    "            img = fit_to_max_size(img, max_width, max_height)\n",
    "\n",
    "        cv2.imshow('Image', img)\n",
    "        k = cv2.waitKey(0)\n",
    "        if k == ord('q'):    # 'q' key to stop\n",
    "            break\n",
    "        elif k == ord('b'):\n",
    "            index = max(0, index - 1)\n",
    "        elif k == ord('n'):\n",
    "            index = min(len_annotations - 1, index + 1)\n",
    "\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def configure_logging(logging_level=logging.INFO):\n",
    "    \"\"\"\n",
    "    Configures logging for the system.\n",
    "\n",
    "    :param logging_level: The logging level to use.\n",
    "    \"\"\"\n",
    "    logger.setLevel(logging_level)\n",
    "\n",
    "    handler = logging.StreamHandler(sys.stdout)\n",
    "    handler.setLevel(logging_level)\n",
    "\n",
    "    logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run from command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the data-set builder from command line, use the following command:\n",
    "`python -m mlcore.via.annotation_viewer [parameters]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following parameters are supported:\n",
    "- `path`: The path to the images to view. (e.g.: *imagesets/segmentation/car_damage/trainval*)\n",
    "- `--annotation`: The path to the VIA annotation file (e.g.: *imagesets/segmentation/car_damage/via_region_data.json*)\n",
    "- `--category-label-key`: The category label key used, default to `category`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "if __name__ == '__main__' and '__file__' in globals():\n",
    "    # for direct shell execution\n",
    "    configure_logging()\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"path\",\n",
    "                        help=\"The path to the images to view.\")\n",
    "    parser.add_argument(\"-a\",\n",
    "                        \"--annotation\",\n",
    "                        help=\"The path to the VIA annotation file.\")\n",
    "    parser.add_argument(\"--max-width\",\n",
    "                        help=\"The maximum width to scale the image for visibility.\",\n",
    "                        type=int,\n",
    "                        default=0)\n",
    "    parser.add_argument(\"--max-height\",\n",
    "                        help=\"The maximum height to scale the image for visibility.\",\n",
    "                        type=int,\n",
    "                        default=0)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    annotations = read_annotations(args.annotation, args.path)\n",
    "    show_annotated_images(annotations, args.max_width, args.max_height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML-Core]",
   "language": "python",
   "name": "conda-env-ML-Core-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
