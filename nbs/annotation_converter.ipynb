{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp annotation_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import logging\n",
    "from mlcore.core import import_modules, parse_known_help\n",
    "from mlcore import annotation as annotation_package\n",
    "from mlcore.annotation.core import AnnotationAdapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation Converter\n",
    "> Annotation Converter Notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def convert(input_annotation_adapter: AnnotationAdapter, output_annotation_adapter: AnnotationAdapter):\n",
    "    \"\"\"\n",
    "    Convert input annotations to output annotations.\n",
    "    `input_annotation_adapter`: the input annotation adapter\n",
    "    `output_annotation_adapter`: the output annotation adapter\n",
    "    \"\"\"\n",
    "    annotations = input_annotation_adapter.read()\n",
    "    output_annotation_adapter.write(annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def configure_logging(logging_level=logging.INFO):\n",
    "    \"\"\"\n",
    "    Configures logging for the system.\n",
    "\n",
    "    :param logging_level: The logging level to use.\n",
    "    \"\"\"\n",
    "    logging.basicConfig(level=logging_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run from command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the data-set builder from command line, use the following command:\n",
    "`python -m mlcore.via.annotation_viewer [parameters]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following parameters are supported:\n",
    "- `path`: The path to the images to view. (e.g.: *imagesets/segmentation/car_damage/trainval*)\n",
    "- `--annotation`: The path to the VIA annotation file (e.g.: *imagesets/segmentation/car_damage/via_region_data.json*)\n",
    "- `--category-label-key`: The category label key used, default to `category`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "if __name__ == '__main__' and '__file__' in globals():\n",
    "    # for direct shell execution\n",
    "    configure_logging()\n",
    "\n",
    "    # read annotation adapters to use\n",
    "    import_modules(annotation_package)\n",
    "    adapter_classes = AnnotationAdapter.__subclasses__()\n",
    "    adapters = dict(zip(map(lambda c: c.__name__, adapter_classes), adapter_classes))\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-i\",\n",
    "                        \"--input\",\n",
    "                        help=\"The annotation input adapter.\",\n",
    "                        type=str,\n",
    "                        choices=adapters.keys(),\n",
    "                        required=True)\n",
    "    parser.add_argument(\"-o\",\n",
    "                        \"--output\",\n",
    "                        help=\"The annotation output adapter.\",\n",
    "                        type=str,\n",
    "                        choices=adapters.keys(),\n",
    "                        required=True)\n",
    "\n",
    "    argv = sys.argv\n",
    "    argv, argv_help_rest = parse_known_help(argv)\n",
    "    args, rest_args = parser.parse_known_args(argv)\n",
    "    argv = rest_args + argv_help_rest\n",
    "    input_adapter_class = adapters[args.input]\n",
    "    output_adapter_class = adapters[args.output]\n",
    "\n",
    "    # parse the input arguments\n",
    "    input_parser = getattr(input_adapter_class, 'argparse')(prefix='input')\n",
    "    argv, argv_help_rest = parse_known_help(argv)\n",
    "    input_args, rest_args = input_parser.parse_known_args(argv)\n",
    "    argv = rest_args + argv_help_rest\n",
    "\n",
    "    # parse the output arguments\n",
    "    output_parser = getattr(output_adapter_class, 'argparse')(prefix='output')\n",
    "    argv, argv_help_rest = parse_known_help(argv)\n",
    "    output_args, rest_args = output_parser.parse_known_args(argv)\n",
    "    argv = rest_args + argv_help_rest\n",
    "\n",
    "    input_adapter = input_adapter_class(input_args)\n",
    "    output_adapter = output_adapter_class(output_args)\n",
    "\n",
    "    convert(input_adapter, output_adapter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted annotation-core.ipynb.\n",
      "Converted annotation-folder_category_adapter.ipynb.\n",
      "Converted annotation-multi_category_adapter.ipynb.\n",
      "Converted annotation-via_adapter.ipynb.\n",
      "Converted annotation-yolo_adapter.ipynb.\n",
      "Converted annotation_converter.ipynb.\n",
      "Converted annotation_viewer.ipynb.\n",
      "Converted category_tools.ipynb.\n",
      "Converted core.ipynb.\n",
      "Converted dataset-core.ipynb.\n",
      "Converted dataset-image_classification.ipynb.\n",
      "Converted dataset-image_object_detection.ipynb.\n",
      "Converted dataset-image_segmentation.ipynb.\n",
      "Converted dataset-type.ipynb.\n",
      "Converted dataset_generator.ipynb.\n",
      "Converted evaluation-core.ipynb.\n",
      "Converted geometry.ipynb.\n",
      "Converted image-color_palette.ipynb.\n",
      "Converted image-inference.ipynb.\n",
      "Converted image-opencv_tools.ipynb.\n",
      "Converted image-pillow_tools.ipynb.\n",
      "Converted image-tools.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted io-core.ipynb.\n",
      "Converted tensorflow-tflite_converter.ipynb.\n",
      "Converted tensorflow-tflite_metadata.ipynb.\n",
      "Converted tensorflow-tfrecord_builder.ipynb.\n",
      "Converted tools-check_double_images.ipynb.\n",
      "Converted tools-downloader.ipynb.\n",
      "Converted tools-image_size_calculator.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "# for generating scripts from notebook directly\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML-Core]",
   "language": "python",
   "name": "conda-env-ML-Core-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
