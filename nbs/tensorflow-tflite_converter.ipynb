{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp tensorflow.tflite_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_metadata' from 'mlcore.tensorflow.tflite_metadata' (/Users/pdc-s-rettig/workspace/PythonProjects/ML-Core/ML-Core/nbs/mlcore/tensorflow/tflite_metadata.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bfa2b8cd4982>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtext_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmlcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmlcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtflite_metadata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_metadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'create_metadata' from 'mlcore.tensorflow.tflite_metadata' (/Users/pdc-s-rettig/workspace/PythonProjects/ML-Core/ML-Core/nbs/mlcore/tensorflow/tflite_metadata.py)"
     ]
    }
   ],
   "source": [
    "# export\n",
    "\n",
    "import logging\n",
    "import logging.handlers\n",
    "import argparse\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from os.path import join\n",
    "from google.protobuf import text_format\n",
    "from mlcore.core import Type, infer_type\n",
    "from mlcore.tensorflow.tflite_metadata import create_metadata, write_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "TFLITE_MODEL_DEFAULT_NAME = 'model.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Lite Model Converter\n",
    "> Converts a SavedModel into Tensorflow Lite format. For details, see [Tensorflow Lite Converter](https://www.tensorflow.org/lite/convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def convert_model(saved_model_dir):\n",
    "    \"\"\"\n",
    "    Convert a SavedModel into Tensorflow Lite Format.\n",
    "    `saved_model_dir`: the path to the SavedModel directory\n",
    "    returns: the converted Tensorflow Lite model\n",
    "    \"\"\"\n",
    "    logger.info('Converting SavedModel from: {}'.format(saved_model_dir))\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)  # path to the SavedModel directory\n",
    "    tflite_model = converter.convert()\n",
    "    return tflite_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def save_model(tflite_model, output_file):\n",
    "    \"\"\"\n",
    "    Save a Tensowflow Lite model to disk.\n",
    "    `tflite_model`: the Tensorflow Lite model\n",
    "    `output_file`: the path and filename to save the Tensorflow Lite model\n",
    "    \"\"\"\n",
    "    with open(output_file, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    logger.info('Successfully save model to file: {}'.format(output_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def read_pipeline_config(pipeline_config_path):\n",
    "    \"\"\"\n",
    "    Reads the pipeline config file.\n",
    "\n",
    "    `pipeline_config_path`: The path to the pipeline config file.\n",
    "    \"\"\"\n",
    "    pipeline_config = {}\n",
    "    with tf.io.gfile.GFile(pipeline_config_path, 'r') as f:\n",
    "        text_format.Parse(f.read(), pipeline_config)\n",
    "    return pipeline_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def configure_logging(logging_level=logging.INFO):\n",
    "    \"\"\"\n",
    "    Configures logging for the system.\n",
    "\n",
    "    `logging_level`: The logging level to use.\n",
    "    \"\"\"\n",
    "    logger.setLevel(logging_level)\n",
    "\n",
    "    handler = logging.StreamHandler(sys.stdout)\n",
    "    handler.setLevel(logging_level)\n",
    "\n",
    "    logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run from command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run from command line, use the following command:\n",
    "`python -m mlcore.tensorflow.tflite_converter [parameters]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following parameters are supported:\n",
    "- `--source`: The path to the folder containing the SavedModel. (e.g.:  *datasets/image_object_detection/car_damage/saved_model*)\n",
    "- `--categories`: The categories file to add to the Tensorflow Lite model. (e.g.:  *datasets/image_object_detection/car_damage/categories.txt*)\n",
    "- `--name`: The name of the model. (e.g.:  *\"SSD MobileNetV2\"*)\n",
    "- `--version`: The version of the model, default to *1* (=v1)\n",
    "- `--type`: The type of the model, if not explicitly set try to infer from categories file path.\n",
    "- `--output`: The folder to store the Tensorflow Lite model. (e.g.:  *datasets/image_object_detection/car_damage/tflite*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "if __name__ == '__main__' and '__file__' in globals():\n",
    "    configure_logging()\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-s\",\n",
    "                        \"--source\",\n",
    "                        help=\"The path to the folder containing the SavedModel.\",\n",
    "                        type=str)\n",
    "    parser.add_argument(\"-c\",\n",
    "                        \"--categories\",\n",
    "                        help=\"The categories file to add to the Tensorflow Lite model.\",\n",
    "                        type=str)\n",
    "    parser.add_argument(\"-n\",\n",
    "                        \"--name\",\n",
    "                        help=\"The name of the model.\",\n",
    "                        type=str)\n",
    "    parser.add_argument(\"-v\",\n",
    "                        \"--version\",\n",
    "                        help=\"The version of the model.\",\n",
    "                        type=int,\n",
    "                        default=1)\n",
    "    parser.add_argument(\"-t\",\n",
    "                        \"--type\",\n",
    "                        help=\"The type of the model, if not explicitly set try to infer from categories file path.\",\n",
    "                        choices=list(Type),\n",
    "                        type=Type,\n",
    "                        default=None)\n",
    "    parser.add_argument(\"-o\",\n",
    "                        \"--output\",\n",
    "                        help=\"The folder to store the Tensorflow Lite model.\",\n",
    "                        type=str)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    model_type = args.type\n",
    "\n",
    "    # try to infer the model type if not explicitly set\n",
    "    if model_type is None:\n",
    "        try:\n",
    "            model_type = infer_type(args.categories)\n",
    "        except ValueError as e:\n",
    "            logger.error(e)\n",
    "            sys.exit(1)\n",
    "\n",
    "    output_file = join(args.output, TFLITE_MODEL_DEFAULT_NAME)\n",
    "\n",
    "    save_model(convert_model(args.source), output_file)\n",
    "\n",
    "    model_meta = create_metadata(args.source, args.categories, model_type, args.name, args.version)\n",
    "    write_metadata(model_meta, output_file, args.categories)\n",
    "\n",
    "    logger.info('FINISHED!!!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML-Core]",
   "language": "python",
   "name": "conda-env-ML-Core-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
