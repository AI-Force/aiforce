{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp annotation.via_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *\n",
    "from nbdev.export import notebook2script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "import shutil\n",
    "import argparse\n",
    "import logging\n",
    "from os.path import join, splitext, getsize, basename, dirname, isfile\n",
    "from mlcore.annotation.core import Annotation, AnnotationAdapter, Region, RegionShape, parse_region_shape\n",
    "from mlcore.io.core import create_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "DEFAULT_ANNOTATIONS_FILE = 'via_region_data.json'\n",
    "DEFAULT_CATEGORY_ID = 'category'\n",
    "CSV_FIELDNAMES = ['#filename', 'file_size', 'file_attributes', 'region_count', 'region_id', 'region_shape_attributes',\n",
    "                  'region_attributes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIA Annotation Adapter\n",
    "> VIA annotation adapter. To use the VIA annotation tool, refer to the [Homepage](http://www.robots.ox.ac.uk/~vgg/software/via/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current supported annotations:\n",
    "- circle\n",
    "- ellipse\n",
    "- point\n",
    "- polyline\n",
    "- rectangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current supported annotation tool versions:\n",
    "- [VIA version 1 (v1.0.6)](https://www.robots.ox.ac.uk/~vgg/software/via/via-1.0.6.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class VIAAdapter(AnnotationAdapter):\n",
    "    \"\"\"\n",
    "    Adapter to read and write annotations in the VIA annotation.\n",
    "    `args`: the arguments containing the parameters\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.files_path = args.files_path\n",
    "        self.annotations_file = args.annotations_file\n",
    "        self.category_label_key = DEFAULT_CATEGORY_ID if args.category_label_key is None else args.category_label_key\n",
    "\n",
    "    def read(self):\n",
    "        \"\"\"\n",
    "        Reads a VIA annotations file.\n",
    "        Supports JSON and CSV file format.\n",
    "        return: the annotations as dictionary\n",
    "        \"\"\"\n",
    "        logger.info('Read annotations from {}'.format(self.annotations_file))\n",
    "\n",
    "        return self._read_v1()\n",
    "\n",
    "    def _read_v1(self):\n",
    "        \"\"\"\n",
    "        Reads a VIA v1 annotations file.\n",
    "        Supports JSON and CSV file format.\n",
    "        return: the annotations as dictionary\n",
    "        \"\"\"\n",
    "        file_extension = splitext(self.annotations_file)[1]\n",
    "\n",
    "        if file_extension.lower() == '.json':\n",
    "            logger.info('Read VIA v1 annotations in JSON format')\n",
    "            annotations = self._read_v1_json()\n",
    "        elif file_extension.lower() == '.csv':\n",
    "            logger.info('Read VIA v1 annotations in CSV format')\n",
    "            annotations = self._read_v1_csv()\n",
    "        else:\n",
    "            message = 'Unsupported annotation format at {}'.format(self.annotations_file)\n",
    "            logger.error(message)\n",
    "            raise ValueError(message)\n",
    "\n",
    "        return annotations\n",
    "\n",
    "    def _read_v1_csv(self):\n",
    "        \"\"\"\n",
    "        Reads a VIA v1 CSV annotations file.\n",
    "        return: the annotations as dictionary\n",
    "        \"\"\"\n",
    "        annotations = {}\n",
    "\n",
    "        with open(self.annotations_file, newline='') as csv_file:\n",
    "            reader = csv.DictReader(csv_file)\n",
    "\n",
    "            skipped_annotations = []\n",
    "            for row in reader:\n",
    "                file_path = join(self.files_path, row['#filename'])\n",
    "                if not isfile(file_path):\n",
    "                    logger.warning(\"{}: Source file not found, skip annotation.\".format(file_path))\n",
    "                    skipped_annotations.append(file_path)\n",
    "                    continue\n",
    "\n",
    "                annotation_id = \"{}{}\".format(row['#filename'], row['file_size'])\n",
    "\n",
    "                if annotation_id not in annotations:\n",
    "                    annotations[annotation_id] = Annotation(annotation_id=annotation_id, file_path=file_path)\n",
    "\n",
    "                annotation = annotations[file_path]\n",
    "\n",
    "                region_shape_attributes = json.loads(row['region_shape_attributes'])\n",
    "                region = self._parse_region_shape_attributes(region_shape_attributes)\n",
    "                region_attributes = json.loads(row['region_attributes'])\n",
    "                category = None\n",
    "                if region_attributes and self.category_label_key in region_attributes:\n",
    "                    category = region_attributes[self.category_label_key]\n",
    "                region.labels = [category] if category else []\n",
    "                annotation.regions.append(region)\n",
    "\n",
    "        logger.info('Finished read annotations')\n",
    "        logger.info('Annotations read: {}'.format(len(annotations)))\n",
    "        if skipped_annotations:\n",
    "            logger.info('Annotations skipped: {}'.format(len(skipped_annotations)))\n",
    "\n",
    "        return annotations\n",
    "\n",
    "    def _read_v1_json(self):\n",
    "        \"\"\"\n",
    "        Reads a VIA v1 JSON annotations file.\n",
    "        return: the annotations as dictionary\n",
    "        \"\"\"\n",
    "        annotations = {}\n",
    "\n",
    "        with open(self.annotations_file) as json_file:\n",
    "            via_annotations = json.load(json_file)\n",
    "\n",
    "            skipped_annotations = []\n",
    "            for data in via_annotations.values():\n",
    "                file_path = join(self.files_path, data['filename'])\n",
    "                if not isfile(file_path):\n",
    "                    logger.warning(\"{}: Source file not found, skip annotation.\".format(file_path))\n",
    "                    skipped_annotations.append(file_path)\n",
    "                    continue\n",
    "\n",
    "                annotation_id = \"{}{}\".format(data['filename'], data['size'])\n",
    "\n",
    "                if annotation_id not in annotations:\n",
    "                    annotations[annotation_id] = Annotation(annotation_id=annotation_id, file_path=file_path)\n",
    "\n",
    "                annotation = annotations[annotation_id]\n",
    "\n",
    "                for region_data in data['regions'].values():\n",
    "                    region_shape_attributes = region_data['shape_attributes']\n",
    "                    region = self._parse_region_shape_attributes(region_shape_attributes)\n",
    "                    region_attributes = region_data['region_attributes']\n",
    "                    category = None\n",
    "                    if region_attributes and self.category_label_key in region_attributes:\n",
    "                        category = region_attributes[self.category_label_key]\n",
    "                    region.labels = [category] if category else []\n",
    "                    annotation.regions.append(annotation)\n",
    "\n",
    "        logger.info('Finished read annotations')\n",
    "        logger.info('Annotations read: {}'.format(len(annotations)))\n",
    "        if skipped_annotations:\n",
    "            logger.info('Annotations skipped: {}'.format(len(skipped_annotations)))\n",
    "\n",
    "        return annotations\n",
    "\n",
    "    def write(self, annotations):\n",
    "        \"\"\"\n",
    "        Writes a VIA annotations file and copy the corresponding source files.\n",
    "        Supports JSON and CSV file format. Format is inferred from the annotations_file setting.\n",
    "        `annotations`: the annotations to write\n",
    "        \"\"\"\n",
    "        target_folder = create_folder(self.files_path)\n",
    "        create_folder(dirname(self.annotations_file))\n",
    "        logger.info('Write annotations to {}'.format(self.annotations_file))\n",
    "        logger.info('Write file sources to {}'.format(target_folder))\n",
    "\n",
    "        self._write_v1(annotations)\n",
    "\n",
    "    def _write_v1(self, annotations):\n",
    "        \"\"\"\n",
    "        Writes a VIA v1 annotations file and copy the corresponding source files.\n",
    "        Supports JSON and CSV file format.\n",
    "        `annotations`: the annotations to write\n",
    "        \"\"\"\n",
    "        file_extension = splitext(self.annotations_file)[1]\n",
    "\n",
    "        if file_extension.lower() == '.json':\n",
    "            logger.info('Write VIA v1 annotations in JSON format')\n",
    "            self._write_v1_json(annotations)\n",
    "        elif file_extension.lower() == '.csv':\n",
    "            logger.info('Write VIA v1 annotations in CSV format')\n",
    "            self._write_v1_csv(annotations)\n",
    "        else:\n",
    "            message = 'Unsupported annotation format at {}'.format(self.annotations_file)\n",
    "            logger.error(message)\n",
    "            raise ValueError(message)\n",
    "\n",
    "    def _write_v1_csv(self, annotations):\n",
    "        \"\"\"\n",
    "        Writes a VIA v1 CSV annotations file and copy the corresponding source files.\n",
    "        `annotations`: the annotations to write\n",
    "        \"\"\"\n",
    "        with open(self.annotations_file, 'w', newline='') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=CSV_FIELDNAMES)\n",
    "            writer.writeheader()\n",
    "\n",
    "            skipped_annotations = []\n",
    "\n",
    "            for annotation in annotations.values():\n",
    "                target_file = join(self.files_path, basename(annotation.file_path))\n",
    "\n",
    "                if not isfile(annotation.file_path):\n",
    "                    logger.warning(\"{}: Source file not found, skip annotation.\".format(annotation.file_path))\n",
    "                    skipped_annotations.append(annotation.file_path)\n",
    "                    continue\n",
    "                if isfile(target_file):\n",
    "                    logger.warning(\"{}: Target file already exist, skip annotation.\".format(annotation.file_path))\n",
    "                    skipped_annotations.append(annotation.file_path)\n",
    "                    continue\n",
    "\n",
    "                file_size = getsize(annotation.file_path)\n",
    "                file_name = basename(annotation.file_path)\n",
    "                for index, region in enumerate(annotation.regions):\n",
    "                    region_shape_attributes = self._create_region_shape_attributes(region)\n",
    "                    region_attributes = {\n",
    "                        self.category_label_key: ' '.join(region.labels) if len(region.labels) else ''\n",
    "                    }\n",
    "\n",
    "                    writer.writerow({'#filename': file_name,\n",
    "                                     'file_size': file_size,\n",
    "                                     'file_attributes': '{}',\n",
    "                                     'region_count': len(annotation.regions),\n",
    "                                     'region_id': str(index),\n",
    "                                     'region_shape_attributes': json.dumps(region_shape_attributes),\n",
    "                                     'region_attributes': json.dumps(region_attributes)})\n",
    "                # copy the file\n",
    "                shutil.copy2(annotation.file_path, target_file)\n",
    "\n",
    "        logger.info('Finished write annotations')\n",
    "        logger.info('Annotations written: {}'.format(len(annotations) - len(skipped_annotations)))\n",
    "        if skipped_annotations:\n",
    "            logger.info('Annotations skipped: {}'.format(len(skipped_annotations)))\n",
    "\n",
    "    def _write_v1_json(self, annotations):\n",
    "        \"\"\"\n",
    "        Writes a VIA v1 JSON annotations file and copy the corresponding source files.\n",
    "        `annotations`: the annotations to write\n",
    "        \"\"\"\n",
    "        json_annotations = {}\n",
    "        skipped_annotations = []\n",
    "\n",
    "        for annotation in annotations.values():\n",
    "            target_file = join(self.files_path, basename(annotation.file_path))\n",
    "\n",
    "            if not isfile(annotation.file_path):\n",
    "                logger.warning(\"{}: Source file not found, skip annotation.\".format(annotation.file_path))\n",
    "                skipped_annotations.append(annotation.file_path)\n",
    "                continue\n",
    "            if isfile(target_file):\n",
    "                logger.warning(\"{}: Target file already exist, skip annotation.\".format(annotation.file_path))\n",
    "                skipped_annotations.append(annotation.file_path)\n",
    "                continue\n",
    "\n",
    "            file_size = getsize(annotation.file_path)\n",
    "            file_name = basename(annotation.file_path)\n",
    "            file_id = '{:s}{:d}'.format(file_name, file_size)\n",
    "            regions = {}\n",
    "            for index, region in enumerate(annotation.regions):\n",
    "                regions[str(index)] = {\n",
    "                    'shape_attributes': self._create_region_shape_attributes(region),\n",
    "                    'region_attributes': {\n",
    "                        self.category_label_key: ' '.join(region.labels) if len(region.labels) else ''\n",
    "                    }\n",
    "                }\n",
    "            json_annotations[file_id] = {\n",
    "                'fileref': \"\",\n",
    "                'size': file_size,\n",
    "                'filename': file_name,\n",
    "                'base64_img_data': \"\",\n",
    "                'file_attributes': '{}',\n",
    "                \"regions\": regions\n",
    "            }\n",
    "            # copy the file\n",
    "            shutil.copy2(annotation.file_path, target_file)\n",
    "\n",
    "        with open(self.annotations_file, 'w') as json_file:\n",
    "            json.dump(json_annotations, json_file)\n",
    "\n",
    "        logger.info('Finished write annotations')\n",
    "        logger.info('Annotations written: {}'.format(len(annotations) - len(skipped_annotations)))\n",
    "        if skipped_annotations:\n",
    "            logger.info('Annotations skipped: {}'.format(len(skipped_annotations)))\n",
    "\n",
    "    @classmethod\n",
    "    def _parse_region_shape_attributes(cls, region_shape_attributes):\n",
    "        \"\"\"\n",
    "        Parse region shape attributes.\n",
    "        `region_shape_attributes`: the region shape attributes as dictionary\n",
    "        return: the corresponding annotation\n",
    "        \"\"\"\n",
    "        if not region_shape_attributes:\n",
    "            return Annotation()\n",
    "\n",
    "        region_shape = parse_region_shape(region_shape_attributes['name'])\n",
    "        points_x = None\n",
    "        points_y = None\n",
    "        radius_x = 0\n",
    "        radius_y = 0\n",
    "        if region_shape == RegionShape.CIRCLE:\n",
    "            points_x = [region_shape_attributes['cx']]\n",
    "            points_y = [region_shape_attributes['cy']]\n",
    "            radius_x = region_shape_attributes['r']\n",
    "            radius_y = region_shape_attributes['r']\n",
    "        elif region_shape == RegionShape.ELLIPSE:\n",
    "            points_x = [region_shape_attributes['cx']]\n",
    "            points_y = [region_shape_attributes['cy']]\n",
    "            radius_x = region_shape_attributes['rx']\n",
    "            radius_y = region_shape_attributes['ry']\n",
    "        elif region_shape == RegionShape.POINT:\n",
    "            points_x = [region_shape_attributes['cx']]\n",
    "            points_y = [region_shape_attributes['cy']]\n",
    "        elif region_shape == RegionShape.POLYGON:\n",
    "            points_x = region_shape_attributes['all_points_x']\n",
    "            points_y = region_shape_attributes['all_points_y']\n",
    "        elif region_shape == RegionShape.RECTANGLE:\n",
    "            x = region_shape_attributes['x']\n",
    "            y = region_shape_attributes['y']\n",
    "            width = region_shape_attributes['width']\n",
    "            height = region_shape_attributes['height']\n",
    "            points_x = [x, x + width]\n",
    "            points_y = [y, y + height]\n",
    "        return Region(shape=region_shape, points_x=points_x, points_y=points_y, radius_x=radius_x, radius_y=radius_y)\n",
    "\n",
    "    @classmethod\n",
    "    def _create_region_shape_attributes(cls, region: Region):\n",
    "        \"\"\"\n",
    "        Create region shape attributes.\n",
    "        `region`: the region to create region shape attributes from\n",
    "        return: the corresponding region shape attributes as dictionary\n",
    "        \"\"\"\n",
    "        region_shape_attributes = {\n",
    "            \"name\": str(region.shape),\n",
    "\n",
    "        }\n",
    "        c_x = region.points_x[0] if len(region.points_x) else 0\n",
    "        c_y = region.points_y[0] if len(region.points_y) else 0\n",
    "\n",
    "        if region.shape == RegionShape.CIRCLE:\n",
    "            region_shape_attributes['cx'] = c_x\n",
    "            region_shape_attributes['cy'] = c_y\n",
    "            region_shape_attributes['r'] = max(region.radius_x, region.radius_y)\n",
    "        elif region.shape == RegionShape.ELLIPSE:\n",
    "            region_shape_attributes['cx'] = c_x\n",
    "            region_shape_attributes['cy'] = c_y\n",
    "            region_shape_attributes['rx'] = region.radius_x\n",
    "            region_shape_attributes['ry'] = region.radius_y\n",
    "        elif region.shape == RegionShape.POINT:\n",
    "            region_shape_attributes['cx'] = c_x\n",
    "            region_shape_attributes['cy'] = c_y\n",
    "        elif region.shape == RegionShape.POLYGON:\n",
    "            region_shape_attributes['all_points_x'] = region.points_x\n",
    "            region_shape_attributes['all_points_y'] = region.points_y\n",
    "        elif region.shape == RegionShape.RECTANGLE:\n",
    "            region_shape_attributes['x'] = region.points_x[0]\n",
    "            region_shape_attributes['y'] = region.points_y[0]\n",
    "            region_shape_attributes['width'] = region.points_x[1] - region.points_x[0]\n",
    "            region_shape_attributes['height'] = region.points_y[1] - region.points_y[0]\n",
    "        return region_shape_attributes\n",
    "\n",
    "    @classmethod\n",
    "    def argparse(cls, prefix=None):\n",
    "        \"\"\"\n",
    "        Returns the argument parser containing argument definition for command line use.\n",
    "        `prefix`: a parameter prefix to set, if needed\n",
    "        return: the argument parser\n",
    "        \"\"\"\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument(cls.assign_prefix('--files_path', prefix),\n",
    "                            dest=\"files_path\",\n",
    "                            help=\"The path to the folder containing the files.\",\n",
    "                            required=True)\n",
    "        parser.add_argument(cls.assign_prefix('--annotations_file', prefix),\n",
    "                            dest=\"annotations_file\",\n",
    "                            help=\"The path to the VIA annotation file.\",\n",
    "                            required=True)\n",
    "        parser.add_argument(cls.assign_prefix('--category_label_key', prefix),\n",
    "                            dest=\"category_label_key\",\n",
    "                            help=\"The key of the category label.\",\n",
    "                            default=DEFAULT_CATEGORY_ID)\n",
    "\n",
    "        return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(VIAAdapter.read)\n",
    "show_doc(VIAAdapter.write)\n",
    "show_doc(VIAAdapter.argparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIA Annotation Tool v1\n",
    "Read or write annotation files made with the [VIA Annotation Tool Version 1](http://www.robots.ox.ac.uk/~vgg/software/via/via-1.0.6.html).\n",
    "Supported annotation file format are JSON and CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def configure_logging(logging_level=logging.INFO):\n",
    "    \"\"\"\n",
    "    Configures logging for the system.\n",
    "\n",
    "    :param logging_level: The logging level to use.\n",
    "    \"\"\"\n",
    "    logger.setLevel(logging_level)\n",
    "\n",
    "    handler = logging.StreamHandler(sys.stdout)\n",
    "    handler.setLevel(logging_level)\n",
    "\n",
    "    logger.addHandler(handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted annotation-core.ipynb.\n",
      "Converted annotation-folder_category_adapter.ipynb.\n",
      "Converted annotation-multi_category_adapter.ipynb.\n",
      "Converted annotation-via_adapter.ipynb.\n",
      "Converted annotation-viewer.ipynb.\n",
      "Converted annotation-yolo_adapter.ipynb.\n",
      "Converted category_tools.ipynb.\n",
      "Converted core.ipynb.\n",
      "Converted dataset-core.ipynb.\n",
      "Converted dataset-image_classification.ipynb.\n",
      "Converted dataset-image_object_detection.ipynb.\n",
      "Converted dataset-image_segmentation.ipynb.\n",
      "Converted dataset-type.ipynb.\n",
      "Converted dataset_generator.ipynb.\n",
      "Converted evaluation-core.ipynb.\n",
      "Converted geometry.ipynb.\n",
      "Converted image-color_palette.ipynb.\n",
      "Converted image-inference.ipynb.\n",
      "Converted image-opencv_tools.ipynb.\n",
      "Converted image-pillow_tools.ipynb.\n",
      "Converted image-tools.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted io-core.ipynb.\n",
      "Converted tensorflow-tflite_converter.ipynb.\n",
      "Converted tensorflow-tflite_metadata.ipynb.\n",
      "Converted tensorflow-tfrecord_builder.ipynb.\n",
      "Converted tools-check_double_images.ipynb.\n",
      "Converted tools-downloader.ipynb.\n",
      "Converted tools-image_size_calculator.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "# for generating scripts from notebook directly\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML-Core]",
   "language": "python",
   "name": "conda-env-ML-Core-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
