{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dataset.image_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import logging\n",
    "from os.path import join\n",
    "from aiforce.core import assign_arg_prefix\n",
    "from aiforce.annotation.core import AnnotationAdapter\n",
    "from aiforce.dataset.core import Dataset\n",
    "from aiforce.tensorflow.tfrecord_builder import create_labelmap_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset for image classification\n",
    "\n",
    "> Creates a dataset for image classification. Single and multi label classification is supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a data-set for a classification or segmentation task. If an annotation file is present, the annotations are also prepared.\n",
    "The data-set is created based on an image-set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image-Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image-sets are collected images to build a data-set from, stored in the `imagesets` folder.\n",
    "The `imagesets` folder contains the following folder structure:\n",
    "- imagesets/*[image_set_type]*/*[image_set_name]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the `[image_set_name]` folder are the following files / folders\n",
    "- `test/`: test images (benchmark)\n",
    "- `trainval/`: training and validation images for [cross validation](https://pdc-pj.backlog.jp/wiki/RAD_RAD/Neural+Network+-+Training)\n",
    "- `categories.txt`: all categories (classes) the image-set contains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data-Set Folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data-sets are stored in the `datasets` base folder.\n",
    "The `datasets` folder contains the following folder structure:\n",
    "- datasets/*[data_set_type]*/*[data_set_name]*\n",
    "where `[data_set_type]` is the same as the corresponding `[image_set_type]` and `[data_set_name]` is the same as the corresponding `[image_set_name]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the `[data_set_name]` folder are the following files / folders\n",
    "- `test/`: test set (benchmark)\n",
    "- `train/`: training set\n",
    "- `val/`: validation set\n",
    "- `categories.txt`: all categories (classes) the data-set contains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a classification data-set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification data-set can be created from a classification image-set. \n",
    "All images are validated, if they belong to one of the given categories. If categories with no images are found or images belong to a category not listed in `categories.txt`, the data-set can not be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class ImageClassificationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Classification dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_adapter: AnnotationAdapter, output_adapter: AnnotationAdapter, split=None, seed=None,\n",
    "                 sample=None, tfrecord=False):\n",
    "        super().__init__(input_adapter, output_adapter, split, seed, sample)\n",
    "        self.tfrecord = tfrecord\n",
    "\n",
    "    @classmethod\n",
    "    def argparse(cls, prefix=None):\n",
    "        \"\"\"\n",
    "        Returns the argument parser containing argument definition for command line use.\n",
    "        `prefix`: a parameter prefix to set, if needed\n",
    "        return: the argument parser\n",
    "        \"\"\"\n",
    "        parser = super(ImageClassificationDataset, cls).argparse(prefix=prefix)\n",
    "        parser.add_argument(assign_arg_prefix(\"--tfrecord\", prefix),\n",
    "                            dest=\"tfrecord\",\n",
    "                            help=\"Also create .tfrecord files.\",\n",
    "                            action=\"store_true\")\n",
    "        return parser\n",
    "\n",
    "    def copy(self, train_annotation_keys, val_annotation_keys, test_files=None):\n",
    "        \"\"\"\n",
    "        Copy the images to the dataset and remove EXIF orientation information by hard-rotate the images.\n",
    "        If tfrecords are build, generate a labelmap.pbtxt file.\n",
    "        `train_annotation_keys`: The list of training annotation keys\n",
    "        `val_annotation_keys`: The list of validation annotation keys\n",
    "        `test_files`: The list of test file paths\n",
    "        return: A tuple containing train, val and test target file paths\n",
    "        \"\"\"\n",
    "\n",
    "        train_targets, val_targets, test_targets = super().copy(train_annotation_keys, val_annotation_keys, test_files)\n",
    "\n",
    "        files = train_targets + val_targets + test_targets\n",
    "        logger.info('Start assign image orientation to {} images'.format(len(files)))\n",
    "        for file in files:\n",
    "            self.assign_orientation(file)\n",
    "        logger.info('Finished assign image orientation to {} images'.format(len(files)))\n",
    "\n",
    "        # if create tfrecord, create a labelmap.pbtxt file containing the categories\n",
    "        if self.tfrecord:\n",
    "            labelmap_file_name = 'label_map.pbtxt'\n",
    "            labelmap_output_file = join(self.output_adapter.path, labelmap_file_name)\n",
    "            logger.info('Generate {}'.format(labelmap_output_file))\n",
    "            create_labelmap_file(labelmap_output_file, list(self.categories), 1)\n",
    "\n",
    "        return train_targets, val_targets, test_targets\n",
    "\n",
    "    def build_info(self):\n",
    "        \"\"\"\n",
    "        Converts annotations\n",
    "        \"\"\"\n",
    "        super().build_info()\n",
    "        logger.info('create_tfrecord: {}'.format(self.tfrecord))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted annotation-core.ipynb.\n",
      "Converted annotation-folder_category_adapter.ipynb.\n",
      "Converted annotation-multi_category_adapter.ipynb.\n",
      "Converted annotation-via_adapter.ipynb.\n",
      "Converted annotation-yolo_adapter.ipynb.\n",
      "Converted annotation_converter.ipynb.\n",
      "Converted annotation_viewer.ipynb.\n",
      "Converted category_tools.ipynb.\n",
      "Converted core.ipynb.\n",
      "Converted dataset-core.ipynb.\n",
      "Converted dataset-image_classification.ipynb.\n",
      "Converted dataset-image_object_detection.ipynb.\n",
      "Converted dataset-image_segmentation.ipynb.\n",
      "Converted dataset-type.ipynb.\n",
      "Converted dataset_generator.ipynb.\n",
      "Converted evaluation-core.ipynb.\n",
      "Converted geometry.ipynb.\n",
      "Converted image-color_palette.ipynb.\n",
      "Converted image-inference.ipynb.\n",
      "Converted image-opencv_tools.ipynb.\n",
      "Converted image-pillow_tools.ipynb.\n",
      "Converted image-tools.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted io-core.ipynb.\n",
      "Converted tensorflow-tflite_converter.ipynb.\n",
      "Converted tensorflow-tflite_metadata.ipynb.\n",
      "Converted tensorflow-tfrecord_builder.ipynb.\n",
      "Converted tools-check_double_images.ipynb.\n",
      "Converted tools-downloader.ipynb.\n",
      "Converted tools-image_size_calculator.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "# for generating scripts from notebook directly\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML-Core]",
   "language": "python",
   "name": "conda-env-ML-Core-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
