{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp annotation_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import sys\n",
    "import argparse\n",
    "import logging\n",
    "from aiforce.core import list_subclasses, parse_known_args_with_help\n",
    "from aiforce import annotation as annotation_package\n",
    "from aiforce.annotation.core import AnnotationAdapter, SubsetType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotation Converter\n",
    "> Converter to covert annotations into different formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/annotation_converter.png\" alt=\"AnnotationConverter\" width=\"800\" caption=\"The Annotation Converter.\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def convert(input_adapter: AnnotationAdapter, output_adapter: AnnotationAdapter):\n",
    "    \"\"\"\n",
    "    Convert input annotations to output annotations.\n",
    "    `input_adapter`: the input annotation adapter\n",
    "    `output_adapter`: the output annotation adapter\n",
    "    \"\"\"\n",
    "    categories = input_adapter.read_categories()\n",
    "    annotations = input_adapter.read_annotations(SubsetType.TRAINVAL)\n",
    "    output_adapter.write_categories(categories)\n",
    "    output_adapter.write_annotations(annotations, SubsetType.TRAINVAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def configure_logging(logging_level=logging.INFO):\n",
    "    \"\"\"\n",
    "    Configures logging for the system.\n",
    "\n",
    "    :param logging_level: The logging level to use.\n",
    "    \"\"\"\n",
    "    logging.basicConfig(level=logging_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run from command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the annotation converter from command line, use the following command:\n",
    "`python -m mlcore.annotation_converter [parameters]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following parameters are supported:\n",
    "- `-i`, `--input_adapter`: The annotation adapter to the annotations to convert from (e.g.: *VIAAnnotationAdapter*)\n",
    "- `-o`, `--output_adapter`: The annotation adapter to the annotations to convert to (e.g.: *MultiCategoryAnnotationAdapter*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "if __name__ == '__main__' and '__file__' in globals():\n",
    "    # for direct shell execution\n",
    "    configure_logging()\n",
    "\n",
    "    # read annotation adapters to use\n",
    "    adapters = list_subclasses(annotation_package, AnnotationAdapter)\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-i\",\n",
    "                        \"--input_adapter\",\n",
    "                        help=\"The annotation adapter to read the annotations.\",\n",
    "                        type=str,\n",
    "                        choices=adapters.keys())\n",
    "    parser.add_argument(\"-o\",\n",
    "                        \"--output_adapter\",\n",
    "                        help=\"The annotation adapter to write the annotations.\",\n",
    "                        type=str,\n",
    "                        choices=adapters.keys())\n",
    "\n",
    "    argv = sys.argv\n",
    "    args, argv = parse_known_args_with_help(parser, argv)\n",
    "    input_adapter_class = adapters[args.input_adapter]\n",
    "    output_adapter_class = adapters[args.output_adapter]\n",
    "\n",
    "    # parse the input arguments\n",
    "    input_parser = getattr(input_adapter_class, 'argparse')(prefix='input')\n",
    "    input_args, argv = parse_known_args_with_help(input_parser, argv)\n",
    "\n",
    "    # parse the output arguments\n",
    "    output_parser = getattr(output_adapter_class, 'argparse')(prefix='output')\n",
    "    output_args, argv = parse_known_args_with_help(output_parser, argv)\n",
    "\n",
    "    convert(input_adapter_class(**vars(input_args)), output_adapter_class(**vars(output_args)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Image Object Detection to Multi Category Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert image object detection annotations to multi category image classifications, run the following command:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`python -m mlcore.annotation_converter --input_adapter VIAAnnotationAdapter --input_path data/image_object_detection/my_collection --output_adapter MultiCategoryAnnotationAdapter --output_path data/image_classification/my_collection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted annotation-core.ipynb.\n",
      "Converted annotation-folder_category_adapter.ipynb.\n",
      "Converted annotation-multi_category_adapter.ipynb.\n",
      "Converted annotation-via_adapter.ipynb.\n",
      "Converted annotation-yolo_adapter.ipynb.\n",
      "Converted annotation_converter.ipynb.\n",
      "Converted annotation_viewer.ipynb.\n",
      "Converted category_tools.ipynb.\n",
      "Converted core.ipynb.\n",
      "Converted dataset-core.ipynb.\n",
      "Converted dataset-image_classification.ipynb.\n",
      "Converted dataset-image_object_detection.ipynb.\n",
      "Converted dataset-image_segmentation.ipynb.\n",
      "Converted dataset-type.ipynb.\n",
      "Converted dataset_generator.ipynb.\n",
      "Converted evaluation-core.ipynb.\n",
      "Converted geometry.ipynb.\n",
      "Converted image-color_palette.ipynb.\n",
      "Converted image-inference.ipynb.\n",
      "Converted image-opencv_tools.ipynb.\n",
      "Converted image-pillow_tools.ipynb.\n",
      "Converted image-tools.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted io-core.ipynb.\n",
      "Converted tensorflow-tflite_converter.ipynb.\n",
      "Converted tensorflow-tflite_metadata.ipynb.\n",
      "Converted tensorflow-tfrecord_builder.ipynb.\n",
      "Converted tools-check_double_images.ipynb.\n",
      "Converted tools-downloader.ipynb.\n",
      "Converted tools-image_size_calculator.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "# for generating scripts from notebook directly\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML-Core]",
   "language": "python",
   "name": "conda-env-ML-Core-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
