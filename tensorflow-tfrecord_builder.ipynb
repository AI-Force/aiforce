{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp tensorflow.tfrecord_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import logging\n",
    "import io\n",
    "import tensorflow as tf\n",
    "from os import environ\n",
    "from os.path import basename\n",
    "from mlcore.image.pillow_tools import get_image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow TFRecord Builder\n",
    "> Creates TFRecord Files and Labelmap protobuffer text files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create TFRecord Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_tfrecord_entry(categories, annotation):\n",
    "    \"\"\"\n",
    "    Create tfrecord entry with annotations for one file / image.\n",
    "    `categories`: the categories used\n",
    "    `annotation`: the annotation of a file / image\n",
    "    return: the tfrecord entry\n",
    "    \"\"\"\n",
    "    with tf.io.gfile.GFile(annotation.file_path, 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    _, width, height = get_image_size(io.BytesIO(encoded_jpg))\n",
    "\n",
    "    file_name = basename(annotation.file_path).encode('utf8')\n",
    "    image_format = b'jpg'\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    for region in annotation.regions:\n",
    "        x_min = min(region.points_x)\n",
    "        y_min = min(region.points_y)\n",
    "        x_max = max(region.points_x)\n",
    "        y_max = max(region.points_y)\n",
    "        category = region.labels[0] if len(region.labels) else ''\n",
    "\n",
    "        xmins.append(x_min / width)\n",
    "        xmaxs.append(x_max / width)\n",
    "        ymins.append(y_min / height)\n",
    "        ymaxs.append(y_max / height)\n",
    "        classes_text.append(category.encode('utf8'))\n",
    "        classes.append(categories.index(category))\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': int64_feature(height),\n",
    "        'image/width': int64_feature(width),\n",
    "        'image/filename': bytes_feature(file_name),\n",
    "        'image/source_id': bytes_feature(file_name),\n",
    "        'image/encoded': bytes_feature(encoded_jpg),\n",
    "        'image/format': bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': float_list_feature(ymaxs),\n",
    "        'image/object/class/text': bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_tfrecord_file(output_path, categories, annotations):\n",
    "    \"\"\"\n",
    "    Create a tfrecord file for a sub-data-set, which can be one of the following: training, validation, test\n",
    "    `output_path`: the path including the filename of the tfrecord file\n",
    "    `categories`: the categories used\n",
    "    `annotations`: the annotations of the files / images\n",
    "    \"\"\"\n",
    "    writer = tf.io.TFRecordWriter(output_path)\n",
    "    for annotation in annotations.values():\n",
    "        tf_example = create_tfrecord_entry(categories, annotation)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "    writer.close()\n",
    "    logger.info('Successfully created the TFRecord file: {}'.format(output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions for creating TFRecord data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "def int64_list_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def bytes_list_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "\n",
    "def float_list_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Labelmap Protobuffer Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_labelmap_file(output_path, categories, start=1):\n",
    "    \"\"\"\n",
    "    Create labelmap protobuffer text file containing the categories.\n",
    "    Format is compatible with Tensorflow Object Detection API.\n",
    "    For object detection data-sets, the categories should exclude the background class and `start` should be 1.\n",
    "    `output_path`: the path including the filename of the protobuffer text file\n",
    "    `categories`: a list of the categories to write\n",
    "    `start`: the category index for the first category\n",
    "    \"\"\"\n",
    "    # create label_map data\n",
    "    label_map = ''\n",
    "    for index, category in enumerate(categories, start=start):\n",
    "        label_map = label_map + \"item {\\n\"\n",
    "        label_map = label_map + \" id: \" + str(index) + \"\\n\"\n",
    "        label_map = label_map + \" name: '\" + category + \"'\\n}\\n\\n\"\n",
    "    label_map = label_map[:-1]\n",
    "\n",
    "    # write label_map file\n",
    "    with open(output_path, \"w\") as f:\n",
    "        f.write(label_map)\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted annotation-core.ipynb.\n",
      "Converted annotation-folder_category_adapter.ipynb.\n",
      "Converted annotation-multi_category_adapter.ipynb.\n",
      "Converted annotation-via_adapter.ipynb.\n",
      "Converted annotation-yolo_adapter.ipynb.\n",
      "Converted annotation_converter.ipynb.\n",
      "Converted annotation_viewer.ipynb.\n",
      "Converted category_tools.ipynb.\n",
      "Converted core.ipynb.\n",
      "Converted dataset-core.ipynb.\n",
      "Converted dataset-image_classification.ipynb.\n",
      "Converted dataset-image_object_detection.ipynb.\n",
      "Converted dataset-image_segmentation.ipynb.\n",
      "Converted dataset-type.ipynb.\n",
      "Converted dataset_generator.ipynb.\n",
      "Converted evaluation-core.ipynb.\n",
      "Converted geometry.ipynb.\n",
      "Converted image-color_palette.ipynb.\n",
      "Converted image-inference.ipynb.\n",
      "Converted image-opencv_tools.ipynb.\n",
      "Converted image-pillow_tools.ipynb.\n",
      "Converted image-tools.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted io-core.ipynb.\n",
      "Converted tensorflow-tflite_converter.ipynb.\n",
      "Converted tensorflow-tflite_metadata.ipynb.\n",
      "Converted tensorflow-tfrecord_builder.ipynb.\n",
      "Converted tools-check_double_images.ipynb.\n",
      "Converted tools-downloader.ipynb.\n",
      "Converted tools-image_size_calculator.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "# for generating scripts from notebook directly\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML-Core]",
   "language": "python",
   "name": "conda-env-ML-Core-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
