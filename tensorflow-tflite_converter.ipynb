{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp tensorflow.tflite_converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import logging\n",
    "import logging.handlers\n",
    "import argparse\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from os.path import join\n",
    "from google.protobuf import text_format\n",
    "from aiforce.dataset.type import DatasetType, infer_dataset_type\n",
    "from aiforce.tensorflow.tflite_metadata import create_metadata, write_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "TFLITE_MODEL_DEFAULT_NAME = 'model.tflite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Lite Model Converter\n",
    "> Converts a SavedModel into Tensorflow Lite format. For details, see [Tensorflow Lite Converter](https://www.tensorflow.org/lite/convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def convert_model(saved_model_dir):\n",
    "    \"\"\"\n",
    "    Convert a SavedModel into Tensorflow Lite Format.\n",
    "    `saved_model_dir`: the path to the SavedModel directory\n",
    "    returns: the converted Tensorflow Lite model\n",
    "    \"\"\"\n",
    "    logger.info('Converting SavedModel from: {}'.format(saved_model_dir))\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)  # path to the SavedModel directory\n",
    "    tflite_model = converter.convert()\n",
    "    return tflite_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def save_model(tflite_model, output_file):\n",
    "    \"\"\"\n",
    "    Save a Tensowflow Lite model to disk.\n",
    "    `tflite_model`: the Tensorflow Lite model\n",
    "    `output_file`: the path and filename to save the Tensorflow Lite model\n",
    "    \"\"\"\n",
    "    with open(output_file, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    logger.info('Successfully save model to file: {}'.format(output_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def read_pipeline_config(pipeline_config_path):\n",
    "    \"\"\"\n",
    "    Reads the pipeline config file.\n",
    "\n",
    "    `pipeline_config_path`: The path to the pipeline config file.\n",
    "    \"\"\"\n",
    "    pipeline_config = {}\n",
    "    with tf.io.gfile.GFile(pipeline_config_path, 'r') as f:\n",
    "        text_format.Parse(f.read(), pipeline_config)\n",
    "    return pipeline_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def configure_logging(logging_level=logging.INFO):\n",
    "    \"\"\"\n",
    "    Configures logging for the system.\n",
    "\n",
    "    `logging_level`: The logging level to use.\n",
    "    \"\"\"\n",
    "    logger.setLevel(logging_level)\n",
    "\n",
    "    handler = logging.StreamHandler(sys.stdout)\n",
    "    handler.setLevel(logging_level)\n",
    "\n",
    "    logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run from command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run from command line, use the following command:\n",
    "`python -m mlcore.tensorflow.tflite_converter [parameters]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following parameters are supported:\n",
    "- `--source`: The path to the folder containing the SavedModel. (e.g.:  *datasets/image_object_detection/car_damage/saved_model*)\n",
    "- `--categories`: The categories file to add to the Tensorflow Lite model. (e.g.:  *datasets/image_object_detection/car_damage/categories.txt*)\n",
    "- `--name`: The name of the model. (e.g.:  *\"SSD MobileNetV2\"*)\n",
    "- `--version`: The version of the model, default to *1* (=v1)\n",
    "- `--type`: The type of the model, if not explicitly set try to infer from categories file path.\n",
    "- `--output`: The folder to store the Tensorflow Lite model. (e.g.:  *datasets/image_object_detection/car_damage/tflite*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "if __name__ == '__main__' and '__file__' in globals():\n",
    "    configure_logging()\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-s\",\n",
    "                        \"--source\",\n",
    "                        help=\"The path to the folder containing the SavedModel.\",\n",
    "                        type=str)\n",
    "    parser.add_argument(\"-c\",\n",
    "                        \"--categories\",\n",
    "                        help=\"The categories file to add to the Tensorflow Lite model.\",\n",
    "                        type=str)\n",
    "    parser.add_argument(\"-n\",\n",
    "                        \"--name\",\n",
    "                        help=\"The name of the model.\",\n",
    "                        type=str)\n",
    "    parser.add_argument(\"-v\",\n",
    "                        \"--version\",\n",
    "                        help=\"The version of the model.\",\n",
    "                        type=int,\n",
    "                        default=1)\n",
    "    parser.add_argument(\"-t\",\n",
    "                        \"--type\",\n",
    "                        help=\"The type of the model, if not explicitly set try to infer from categories file path.\",\n",
    "                        choices=list(DatasetType),\n",
    "                        type=DatasetType,\n",
    "                        default=None)\n",
    "    parser.add_argument(\"-o\",\n",
    "                        \"--output\",\n",
    "                        help=\"The folder to store the Tensorflow Lite model.\",\n",
    "                        type=str)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    model_type = args.type\n",
    "\n",
    "    # try to infer the model type if not explicitly set\n",
    "    if model_type is None:\n",
    "        try:\n",
    "            model_type = infer_dataset_type(args.categories)\n",
    "        except ValueError as e:\n",
    "            logger.error(e)\n",
    "            sys.exit(1)\n",
    "\n",
    "    output_file = join(args.output, TFLITE_MODEL_DEFAULT_NAME)\n",
    "\n",
    "    save_model(convert_model(args.source), output_file)\n",
    "\n",
    "    model_meta = create_metadata(args.source, args.categories, model_type, args.name, args.version)\n",
    "    write_metadata(model_meta, output_file, args.categories)\n",
    "\n",
    "    logger.info('FINISHED!!!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted annotation-core.ipynb.\n",
      "Converted annotation-folder_category_adapter.ipynb.\n",
      "Converted annotation-multi_category_adapter.ipynb.\n",
      "Converted annotation-via_adapter.ipynb.\n",
      "Converted annotation-yolo_adapter.ipynb.\n",
      "Converted annotation_converter.ipynb.\n",
      "Converted annotation_viewer.ipynb.\n",
      "Converted category_tools.ipynb.\n",
      "Converted core.ipynb.\n",
      "Converted dataset-core.ipynb.\n",
      "Converted dataset-image_classification.ipynb.\n",
      "Converted dataset-image_object_detection.ipynb.\n",
      "Converted dataset-image_segmentation.ipynb.\n",
      "Converted dataset-type.ipynb.\n",
      "Converted dataset_generator.ipynb.\n",
      "Converted evaluation-core.ipynb.\n",
      "Converted geometry.ipynb.\n",
      "Converted image-color_palette.ipynb.\n",
      "Converted image-inference.ipynb.\n",
      "Converted image-opencv_tools.ipynb.\n",
      "Converted image-pillow_tools.ipynb.\n",
      "Converted image-tools.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted io-core.ipynb.\n",
      "Converted tensorflow-tflite_converter.ipynb.\n",
      "Converted tensorflow-tflite_metadata.ipynb.\n",
      "Converted tensorflow-tfrecord_builder.ipynb.\n",
      "Converted tools-check_double_images.ipynb.\n",
      "Converted tools-downloader.ipynb.\n",
      "Converted tools-image_size_calculator.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "# for generating scripts from notebook directly\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML-Core]",
   "language": "python",
   "name": "conda-env-ML-Core-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
