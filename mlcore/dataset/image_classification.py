# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/dataset-image_classification.ipynb (unless otherwise specified).

__all__ = ['CATEGORY_LABEL_KEY', 'DEFAULT_CATEGORIES_FILE', 'DEFAULT_CLASSIFICATION_ANNOTATIONS_FILE',
           'DEFAULT_SEGMENTATION_ANNOTATIONS_FILE', 'DEFAULT_SPLIT', 'DATA_SET_FOLDER', 'SEMANTIC_MASK_FOLDER',
           'TRAIN_VAL_FOLDER', 'TRAIN_FOLDER', 'VAL_FOLDER', 'TEST_FOLDER', 'NOT_CATEGORIZED', 'logger',
           'ClassificationDataSet', 'configure_logging', 'build_data_set']

# Cell

import sys
import argparse
import logging
from os.path import join, dirname, basename
from datetime import datetime
from logging.handlers import MemoryHandler
from ..core import Type, infer_type
from ..annotation.folder_category_adapter import read_annotations as folder_category_read_annotations
from ..annotation.multi_category_adapter import read_annotations as multi_category_read_annotations
from ..annotation.multi_category_adapter import write_annotations as multi_category_write_annotations
from .core import DataSet

# Cell

CATEGORY_LABEL_KEY = 'category'
DEFAULT_CATEGORIES_FILE = 'categories.txt'
DEFAULT_CLASSIFICATION_ANNOTATIONS_FILE = 'annotations.csv'
DEFAULT_SEGMENTATION_ANNOTATIONS_FILE = 'via_region_data.json'
DEFAULT_SPLIT = 0.2
DATA_SET_FOLDER = 'datasets'
SEMANTIC_MASK_FOLDER = 'semantic_masks'
TRAIN_VAL_FOLDER = 'trainval'
TRAIN_FOLDER = 'train'
VAL_FOLDER = 'val'
TEST_FOLDER = 'test'
NOT_CATEGORIZED = '[NOT_CATEGORIZED]'

# Cell

logger = logging.getLogger(__name__)

# Cell


class ClassificationDataSet(DataSet):
    """
    Classification data-set.
    `name`: The name of the data-set.
    `base_path`: The data-set base-path.
    `image_set_path`: The image-set source path.
    `categories_path`: The path to the categories.txt file.
    `data_set_type`: The type of the data-set.
    `annotations_path`: The path to the annotations-file.
    """

    def __init__(self, name, base_path, image_set_path, categories_path, data_set_type, annotations_path=None,
                 create_tfrecord=False):
        super().__init__(name, base_path, image_set_path, categories_path, data_set_type, create_tfrecord)
        self.annotations_path = annotations_path
        # if no annotation file exist, generate annotations based on the folder names
        if not annotations_path:
            self.annotations = folder_category_read_annotations(self.train_val_folder)
        else:
            self.annotations = multi_category_read_annotations(annotations_path, self.train_val_folder)

    def copy(self, train_file_keys, val_file_keys, test_file_names=None):
        """
        Copy the images to the data-set, generate the annotations for train and val images.
        `train_file_keys`: The list of training image keys
        `val_file_keys`: The list of validation image keys
        `test_file_names`: The list of test image file names
        return: A tuple containing train and val annotations
        """

        annotations_train, annotations_val = super().copy(train_file_keys, val_file_keys, test_file_names)

        # write the split train annotations
        if annotations_train:
            annotations_target_path = join(self.train_folder, DEFAULT_CLASSIFICATION_ANNOTATIONS_FILE)
            self.logger.info('Write annotations to {}'.format(annotations_target_path))
            multi_category_write_annotations(annotations_target_path, annotations_train)

        # write the split val annotations
        if annotations_val:
            annotations_target_path = join(self.val_folder, DEFAULT_SEGMENTATION_ANNOTATIONS_FILE)
            self.logger.info('Write annotations to {}'.format(annotations_target_path))
            multi_category_write_annotations(annotations_target_path, annotations_val)

        return annotations_train, annotations_val

# Cell


def configure_logging(logging_level=logging.INFO):
    """
    Configures logging for the system.
    """
    log_memory_handler = MemoryHandler(1, flushLevel=logging_level)
    log_memory_handler.setLevel(logging_level)

    stdout_handler = logging.StreamHandler(sys.stdout)
    stdout_handler.setLevel(logging_level)

    logger.addHandler(log_memory_handler)
    logger.addHandler(stdout_handler)

    logger.setLevel(logging_level)

    return log_memory_handler

# Cell


def build_data_set(category_file_path, output, annotation_file_path=None, split=DEFAULT_SPLIT, seed=None, sample=0,
                   data_set_type=None, create_tfrecord=False, join_overlapping_regions=False,
                   annotation_area_threshold=None, data_set_name=None):
    """
    Build the data-set for training, Validation and test
    `category_file_path`: the filename of the categories file
    `output`: the dataset base folder to build the dataset in
    `annotation_file_path`: the file path to the annotation file
    `split`: the size of the validation set as percentage
    `seed`: random seed to reproduce splits
    `sample`: the size of the sample set as percentage
    `data_set_type`: the type of the data-set, if not set infer from the category file path
    `create_tfrecord`: Also create .tfrecord files.
    `join_overlapping_regions`: Whether overlapping regions of same category should be joined.
    `annotation_area_threshold`: Keep only annotations with minimum size (width or height) related to image size
    `data_set_name`: the name of the data-set, if not set infer from the category file path
    """
    log_memory_handler = configure_logging()

    # try to infer the data-set type if not explicitly set
    if data_set_type is None:
        try:
            data_set_type = infer_type(category_file_path)
        except ValueError as e:
            logger.error(e)
            return

    path = dirname(category_file_path)

    # try to infer the data-set name if not explicitly set
    if data_set_name is None:
        data_set_name = basename(path)

    logger.info('Build parameters:')
    logger.info(' '.join(sys.argv[1:]))
    logger.info('Build configuration:')
    logger.info('category_file_path: {}'.format(category_file_path))
    logger.info('annotation_file_path: {}'.format(annotation_file_path))
    logger.info('split: {}'.format(split))
    logger.info('seed: {}'.format(seed))
    logger.info('sample: {}'.format(sample))
    logger.info('type: {}'.format(data_set_type))
    logger.info('output: {}'.format(output))
    logger.info('join_overlapping_regions: {}'.format(join_overlapping_regions))
    logger.info('annotation_area_threshold: {}'.format(annotation_area_threshold))
    logger.info('name: {}'.format(data_set_name))

    data_set = None
    logger.info('Start build {} data-set {} at {}'.format(data_set_type, data_set_name, output))

    if data_set_type == Type.IMAGE_CLASSIFICATION:
        data_set = ClassificationDataSet(data_set_name, output, path, category_file_path, data_set_type,
                                         annotation_file_path)
    elif data_set_type == Type.IMAGE_SEGMENTATION:
        data_set = SegmentationDataSet(data_set_name, output, path, category_file_path, data_set_type,
                                       annotation_file_path)
    elif data_set_type == Type.IMAGE_OBJECT_DETECTION:
        data_set = ObjectDetectionDataSet(data_set_name, output, path, category_file_path, data_set_type,
                                          annotation_file_path, create_tfrecord, join_overlapping_regions,
                                          annotation_area_threshold)

    if data_set:
        # create the data set folders
        logger.info("Start create the data-set folders at {}".format(data_set.base_path))
        data_set.create_folders()
        logger.info("Finished create the data-set folders at {}".format(data_set.base_path))

        # create the build log file
        log_file_name = datetime.now().strftime("build_%Y.%m.%d-%H.%M.%S.log")
        file_handler = logging.FileHandler(join(data_set.folder, log_file_name), encoding="utf-8")
        log_memory_handler.setTarget(file_handler)

        # build the data set
        data_set.build(split, seed, sample)

    logger.info('Finished build {} data-set {} at {}'.format(data_set_type, data_set_name, output))

# Cell


if __name__ == '__main__' and '__file__' in globals():
    # for direct shell execution
    parser = argparse.ArgumentParser()
    parser.add_argument("categories",
                        help="The path to the image-set categories file.")
    parser.add_argument("--annotation",
                        help="The path to the image-set annotation file, the data-set is build from.",
                        default=None)
    parser.add_argument("--split",
                        help="Percentage of the data which belongs to validation set.",
                        type=float,
                        default=0.2)
    parser.add_argument("--seed",
                        help="A random seed to reproduce splits.",
                        type=int,
                        default=None)
    parser.add_argument("--category-label-key",
                        help="The key of the category name.",
                        default=CATEGORY_LABEL_KEY)
    parser.add_argument("--sample",
                        help="Percentage of the data which will be copied as a sample set.",
                        type=float,
                        default=0)
    parser.add_argument("--type",
                        help="The type of the data-set, if not explicitly set try to infer from categories file path.",
                        choices=list(Type),
                        type=Type,
                        default=None)
    parser.add_argument("--tfrecord",
                        help="Also create .tfrecord files.",
                        action="store_true")
    parser.add_argument("--join-overlapping-regions",
                        help="Whether overlapping regions of same category should be joined.",
                        action="store_true")
    parser.add_argument("--annotation-area-thresh",
                        help="Keep only annotations with minimum size (width or height) related to image size.",
                        type=float,
                        default=None)
    parser.add_argument("--output",
                        help="The path of the data-set folder.",
                        default=DATA_SET_FOLDER)
    parser.add_argument("--name",
                        help="The name of the data-set, if not explicitly set try to infer from categories file path.",
                        default=None)
    args = parser.parse_args()

    CATEGORY_LABEL_KEY = args.category_label_key

    build_data_set(args.categories, args.output, args.annotation, args.split, args.seed, args.sample, args.type,
                   args.tfrecord, args.join_overlapping_regions, args.annotation_area_thresh, args.name)
