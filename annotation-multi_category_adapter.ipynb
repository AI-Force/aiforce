{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp annotation.multi_category_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import csv\n",
    "import shutil\n",
    "import logging\n",
    "from os.path import join, basename, isfile, splitext\n",
    "from aiforce.core import assign_arg_prefix\n",
    "from aiforce.io.core import create_folder\n",
    "from aiforce.annotation.core import Annotation, AnnotationAdapter, Region, SubsetType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "DEFAULT_ANNOTATIONS_FILE = 'annotations.csv'\n",
    "CSV_FIELDNAMES = ['image_name', 'tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Category Annotation Adapter\n",
    "> Adapter to read and write annotations for multi label classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adapter has the following parameters:\n",
    "- `--path`: the path to the base folder containing the annotations (e.g.: *data/image_classification/my_collection*)\n",
    "- `--categories_file_name`: tThe path to the categories file if not set, default to *categories.txt*\n",
    "- `--annotations_file_name`: The name of annotations file. if not set, default to *annotations.csv*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MultiCategoryAnnotationAdapter(AnnotationAdapter):\n",
    "    \"\"\"\n",
    "    Adapter to read and write annotations for multi label classification.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, path, categories_file_name=None, annotations_file_name=None):\n",
    "        \"\"\"\n",
    "        Multi Label Classification Adapter to read and write annotations.\n",
    "        `path`: the folder containing the annotations\n",
    "        `categories_file_name`: the name of the categories file\n",
    "        `annotations_file_name`: the name of annotations file\n",
    "        \"\"\"\n",
    "        super().__init__(path, categories_file_name)\n",
    "\n",
    "        if annotations_file_name is None:\n",
    "            self.annotations_file_name = DEFAULT_ANNOTATIONS_FILE\n",
    "        else:\n",
    "            self.annotations_file_name = annotations_file_name\n",
    "\n",
    "    @classmethod\n",
    "    def argparse(cls, prefix=None):\n",
    "        \"\"\"\n",
    "        Returns the argument parser containing argument definition for command line use.\n",
    "        `prefix`: a parameter prefix to set, if needed\n",
    "        return: the argument parser\n",
    "        \"\"\"\n",
    "        parser = super(MultiCategoryAnnotationAdapter, cls).argparse(prefix=prefix)\n",
    "        parser.add_argument(assign_arg_prefix('--annotations_file', prefix),\n",
    "                            dest=\"annotations_file_name\",\n",
    "                            help=\"The name of the multi classification CSV annotation file.\",\n",
    "                            default=None)\n",
    "        return parser\n",
    "\n",
    "    def read_annotations(self, subset_type=SubsetType.TRAINVAL):\n",
    "        \"\"\"\n",
    "        Read annotations from a multi classification CSV annotations file.\n",
    "        `subset_type`: the subset type to read\n",
    "        return: the annotations as dictionary\n",
    "        \"\"\"\n",
    "        path = join(self.path, str(subset_type))\n",
    "        annotations_file_name = self._annotation_file_name_suffix_handling(subset_type)\n",
    "        annotations_file_path = join(self.path, annotations_file_name)\n",
    "        logger.info('Read file sources from {}'.format(path))\n",
    "        logger.info('Read annotations from {}'.format(annotations_file_path))\n",
    "\n",
    "        annotations = {}\n",
    "\n",
    "        with open(annotations_file_path, newline='') as csv_file:\n",
    "            reader = csv.DictReader(csv_file)\n",
    "\n",
    "            skipped_annotations = []\n",
    "            for row in reader:\n",
    "                file_path = join(path, row['image_name'])\n",
    "                if not isfile(file_path):\n",
    "                    logger.warning(\"{}: Source file not found, skip annotation.\".format(file_path))\n",
    "                    skipped_annotations.append(file_path)\n",
    "                    continue\n",
    "\n",
    "                if file_path not in annotations:\n",
    "                    annotations[file_path] = Annotation(annotation_id=file_path, file_path=file_path)\n",
    "\n",
    "                annotation = annotations[file_path]\n",
    "\n",
    "                tags = row['tags'] if 'tags' in row else []\n",
    "                for category in tags.split(' '):\n",
    "                    region = Region(labels=[category])\n",
    "                    annotation.regions.append(region)\n",
    "\n",
    "        logger.info('Finished read annotations')\n",
    "        logger.info('Annotations read: {}'.format(len(annotations)))\n",
    "        if skipped_annotations:\n",
    "            logger.info('Annotations skipped: {}'.format(len(skipped_annotations)))\n",
    "        return annotations\n",
    "\n",
    "    def write_annotations(self, annotations, subset_type=SubsetType.TRAINVAL):\n",
    "        \"\"\"\n",
    "        Writes a multi classification CSV annotations file and copy the corresponding source files.\n",
    "        `annotations`: the annotations as dictionary\n",
    "        `subset_type`: the subset type to write\n",
    "        return: a list of written target file paths\n",
    "        \"\"\"\n",
    "        path = join(self.path, str(subset_type))\n",
    "        target_folder = create_folder(path)\n",
    "        annotations_file_name = self._annotation_file_name_suffix_handling(subset_type)\n",
    "        annotations_file_path = join(self.path, annotations_file_name)\n",
    "        logger.info('Write file sources to {}'.format(target_folder))\n",
    "        logger.info('Write annotations to {}'.format(annotations_file_path))\n",
    "\n",
    "        skipped_annotations = []\n",
    "        copied_files = []\n",
    "        rows = {}\n",
    "        for annotation in annotations.values():\n",
    "            target_file_name = basename(annotation.file_path)\n",
    "            target_file = join(target_folder, target_file_name)\n",
    "\n",
    "            if not isfile(annotation.file_path):\n",
    "                logger.warning(\"{}: Source file not found, skip annotation.\".format(annotation.file_path))\n",
    "                skipped_annotations.append(annotation.file_path)\n",
    "                continue\n",
    "\n",
    "            # copy the file\n",
    "            if target_file_name not in rows:\n",
    "                rows[target_file_name] = []\n",
    "            rows[target_file_name].extend(annotation.labels())\n",
    "\n",
    "            if isfile(target_file):\n",
    "                logger.warning(\"{}: Target file already exist, skip annotation.\".format(annotation.file_path))\n",
    "                skipped_annotations.append(annotation.file_path)\n",
    "                continue\n",
    "            shutil.copy2(annotation.file_path, target_file)\n",
    "            copied_files.append(target_file)\n",
    "        with open(annotations_file_path, 'w', newline='') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=CSV_FIELDNAMES, delimiter=',', quotechar='\"',\n",
    "                                    quoting=csv.QUOTE_MINIMAL)\n",
    "            writer.writeheader()\n",
    "            writer.writerows([dict(zip(CSV_FIELDNAMES, [key, ' '.join(labels)])) for key, labels in rows.items()])\n",
    "\n",
    "        logger.info('Finished write annotations')\n",
    "        logger.info('Annotations written: {}'.format(len(annotations) - len(skipped_annotations)))\n",
    "        if skipped_annotations:\n",
    "            logger.info('Annotations skipped: {}'.format(len(skipped_annotations)))\n",
    "        return copied_files\n",
    "\n",
    "    def _annotation_file_name_suffix_handling(self, subset_type):\n",
    "        \"\"\"\n",
    "        Handle annotations file name based on the subset type.\n",
    "        `subset_type`: the subset type to handle\n",
    "        return: the annotations file name\n",
    "        \"\"\"\n",
    "        file_name, ext = splitext(self.annotations_file_name)\n",
    "        if subset_type in [SubsetType.TRAIN, SubsetType.VAL] and not file_name.endswith(str(subset_type)):\n",
    "            suffix = \"_{}\".format(str(subset_type))\n",
    "            return \"{}{}{}\".format(file_name, suffix, ext)\n",
    "        return self.annotations_file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(MultiCategoryAnnotationAdapter.list_files)\n",
    "show_doc(MultiCategoryAnnotationAdapter.read_annotations)\n",
    "show_doc(MultiCategoryAnnotationAdapter.read_categories)\n",
    "show_doc(MultiCategoryAnnotationAdapter.write_files)\n",
    "show_doc(MultiCategoryAnnotationAdapter.write_annotations)\n",
    "show_doc(MultiCategoryAnnotationAdapter.write_categories)\n",
    "show_doc(MultiCategoryAnnotationAdapter.argparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted annotation-core.ipynb.\n",
      "Converted annotation-folder_category_adapter.ipynb.\n",
      "Converted annotation-multi_category_adapter.ipynb.\n",
      "Converted annotation-via_adapter.ipynb.\n",
      "Converted annotation-yolo_adapter.ipynb.\n",
      "Converted annotation_converter.ipynb.\n",
      "Converted annotation_viewer.ipynb.\n",
      "Converted category_tools.ipynb.\n",
      "Converted core.ipynb.\n",
      "Converted dataset-core.ipynb.\n",
      "Converted dataset-image_classification.ipynb.\n",
      "Converted dataset-image_object_detection.ipynb.\n",
      "Converted dataset-image_segmentation.ipynb.\n",
      "Converted dataset-type.ipynb.\n",
      "Converted dataset_generator.ipynb.\n",
      "Converted evaluation-core.ipynb.\n",
      "Converted geometry.ipynb.\n",
      "Converted image-color_palette.ipynb.\n",
      "Converted image-inference.ipynb.\n",
      "Converted image-opencv_tools.ipynb.\n",
      "Converted image-pillow_tools.ipynb.\n",
      "Converted image-tools.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted io-core.ipynb.\n",
      "Converted tensorflow-tflite_converter.ipynb.\n",
      "Converted tensorflow-tflite_metadata.ipynb.\n",
      "Converted tensorflow-tfrecord_builder.ipynb.\n",
      "Converted tools-check_double_images.ipynb.\n",
      "Converted tools-downloader.ipynb.\n",
      "Converted tools-image_size_calculator.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "\n",
    "# for generating scripts from notebook directly\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML-Core]",
   "language": "python",
   "name": "conda-env-ML-Core-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
